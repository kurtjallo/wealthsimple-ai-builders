---
phase: 10-demo-polish-deliverables
plan: 05
type: execute
wave: 3
depends_on: ["10-01", "10-02", "10-03", "10-04"]
files_modified:
  - .planning/deliverables/QA-CHECKLIST.md
autonomous: false

must_haves:
  truths:
    - "Every critical user flow works end-to-end on the production deployment"
    - "All 5 demo cases display correctly with expected data"
    - "Agent visualization shows correct statuses for each case"
    - "Decision workflow (approve/deny/escalate) functions on production"
    - "No console errors, 500 responses, or broken UI states"
    - "Demo video is recorded and exported"
    - "All 3 deliverables are ready for submission: URL, video, explanation"
  artifacts:
    - path: ".planning/deliverables/QA-CHECKLIST.md"
      provides: "Comprehensive QA checklist covering all demo flows and deliverables"
      contains: "Case Queue"
  key_links:
    - from: ".planning/deliverables/QA-CHECKLIST.md"
      to: "production URL"
      via: "all checks run against production deployment"
      pattern: "vercel.app"
---

<objective>
Final QA pass across the entire production deployment and all deliverables. Run through every critical flow, fix any bugs found, and verify all three submission deliverables are complete and polished.

Purpose: This is the last line of defense before submission. Every bug, broken link, or missing piece found here saves a failed demo impression. The QA checklist ensures nothing is missed.

Output: A verified, bug-free production deployment with all three deliverables confirmed ready: working prototype URL, demo video, and 500-word explanation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/deliverables/DEMO-SCRIPT.md
@.planning/deliverables/EXPLANATION.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create QA checklist and run automated checks</name>
  <files>.planning/deliverables/QA-CHECKLIST.md</files>
  <action>
    Create `.planning/deliverables/QA-CHECKLIST.md` with the comprehensive QA checklist, then run all automated checks against the production deployment.

    ```markdown
    # Final QA Checklist — KYC/AML Operations Orchestrator

    **Production URL**: [FILL IN from 10-02 summary]
    **Date**: [Current date]
    **Status**: [ ] PASS / [ ] FAIL

    ---

    ## 1. Production Health

    - [ ] `/api/health` returns `{"status":"ok"}` with all checks passing
    - [ ] Page loads in under 3 seconds
    - [ ] No 500 errors on any page
    - [ ] No console errors in browser DevTools
    - [ ] HTTPS certificate valid (Vercel provides this automatically)

    ## 2. Case Queue

    - [ ] Case queue page loads and displays 5 demo cases
    - [ ] Cases show correct statuses: approved (1), escalated (1), review (2), processing (1)
    - [ ] Risk level badges display with correct colors: green (low), yellow (medium), orange (high), red (critical)
    - [ ] Case queue is sorted (most recent first, or by status priority)
    - [ ] Clicking a case navigates to the risk profile view

    ## 3. Case Detail — Sarah Chen (Case 1: Approved, Low Risk)

    - [ ] Risk score displays as 12/100 with "Low" badge (green)
    - [ ] Agent results section shows all 5 agents as "completed" (green)
    - [ ] Document processor results show passport + utility bill with confidence scores
    - [ ] Identity verifier shows "verified" with 0 discrepancies
    - [ ] Sanctions screener shows "no matches" against OFAC, UN, PEP
    - [ ] Risk factors breakdown visible with weights
    - [ ] Case narrative text displays (multi-paragraph, not placeholder)
    - [ ] Decision section shows "Approved" with officer justification
    - [ ] Audit trail shows complete lifecycle (created -> processed -> reviewed -> approved)

    ## 4. Case Detail — Viktor Petrov (Case 2: Escalated, Critical Risk)

    - [ ] Risk score displays as 87/100 with "Critical" badge (red)
    - [ ] Sanctions screener shows match: OFAC SDN, 94% similarity, SDGT program
    - [ ] Case narrative warns about sanctions match
    - [ ] Decision section shows "Escalated" with officer justification mentioning STR
    - [ ] Audit trail shows escalation entry

    ## 5. Case Detail — Amara Okafor (Case 3: In Review, Medium Risk)

    - [ ] Risk score displays as 45/100 with "Medium" badge (yellow)
    - [ ] Document processor shows low confidence (0.62) for driver's license
    - [ ] Identity verifier shows discrepancy (abbreviated name)
    - [ ] Decision section is empty (awaiting officer review)
    - [ ] Approve/Deny/Escalate buttons are functional (if implemented)

    ## 6. Case Detail — Maria Gonzalez-Rivera (Case 4: In Review, High Risk)

    - [ ] Risk score displays as 68/100 with "High" badge (orange)
    - [ ] Sanctions screener shows PEP match (diplomat)
    - [ ] Case narrative mentions enhanced due diligence for PEP status
    - [ ] Decision section is empty (awaiting officer review)

    ## 7. Case Detail — James Oduya (Case 5: Processing)

    - [ ] Status shows "Processing"
    - [ ] Agent visualization shows mixed statuses: some completed, some running, some pending
    - [ ] Document processor shows completed (passport processed)
    - [ ] Identity verifier and sanctions screener show "running"
    - [ ] Risk scorer and case narrator show "pending"
    - [ ] No risk score displayed yet (null)

    ## 8. Agent Visualization

    - [ ] Agent status indicators use distinct visual states: pending (gray), running (blue/animated), completed (green), failed (red)
    - [ ] Parallel agents visually appear to run simultaneously
    - [ ] Animations are smooth (no janky transitions)

    ## 9. Decision Workflow

    - [ ] Approve/Deny/Escalate buttons visible on review cases
    - [ ] Justification field is required (cannot submit without text)
    - [ ] Making a decision updates case status immediately
    - [ ] Decision recorded in audit trail
    - [ ] AI does NOT have approve/deny buttons — only human officers

    ## 10. Audit Trail

    - [ ] Audit log entries visible for decided cases
    - [ ] Each entry has: timestamp, action, actor type (system/agent/officer), details
    - [ ] Entries are in chronological order
    - [ ] Agent actions show agent type as actor

    ## 11. UI Polish

    - [ ] No broken layouts or overflow issues
    - [ ] Text is readable (no truncation hiding important data)
    - [ ] Loading states appear when data is being fetched
    - [ ] Empty states handled gracefully (no blank screens)
    - [ ] Consistent typography and spacing throughout

    ## 12. Deliverables

    - [ ] **Prototype URL**: [URL] accessible and functional
    - [ ] **Demo video**: Recorded, ~2-3 minutes, shows full case lifecycle
    - [ ] **500-word explanation**: Written, covers all 4 required topics, word count 450-550

    ---

    ## Bug Log

    | # | Severity | Description | Page/Component | Status |
    |---|----------|-------------|----------------|--------|
    | 1 | | | | |

    ## Sign-off

    - [ ] All critical checks pass
    - [ ] All deliverables ready
    - [ ] Ready for submission
    ```

    After creating the checklist, run automated checks:

    1. Hit the production health endpoint:
    ```bash
    curl -s https://YOUR-APP.vercel.app/api/health | python3 -m json.tool
    ```

    2. Check that the main page returns HTML:
    ```bash
    curl -s -o /dev/null -w "%{http_code}" https://YOUR-APP.vercel.app
    ```
    Expected: 200

    3. Check key API endpoints return data:
    ```bash
    # Check cases endpoint (if it exists)
    curl -s https://YOUR-APP.vercel.app/api/cases | python3 -m json.tool
    ```

    4. For each check that can be automated, run it and record the result in the checklist.

    5. For any failures found, note them in the Bug Log table with severity (blocker/major/minor) and description.
  </action>
  <verify>
    - `.planning/deliverables/QA-CHECKLIST.md` exists with all sections
    - Health check returns OK from production
    - Main page returns HTTP 200
    - No 500 errors on automated checks
    - Any bugs found are logged in the Bug Log table
  </verify>
  <done>
    QA checklist created and automated checks executed. All automatable verifications run against production deployment. Bug log captures any issues found.
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix any bugs found during QA</name>
  <files></files>
  <action>
    Based on the bugs found in Task 1's QA checklist:

    1. Review the Bug Log from the QA checklist
    2. Prioritize: Fix all blockers and major issues. Minor issues can be noted but skipped if time is tight.
    3. For each bug:
       a. Identify the root cause (read the relevant source files)
       b. Implement the fix
       c. Test the fix locally (`npm run dev`)
       d. Commit the fix with a descriptive message
    4. After all fixes are committed:
       a. Run `npm run build` to verify no new build errors
       b. Redeploy to Vercel: `vercel --prod`
       c. Re-run the failing checks from Task 1 to verify they pass

    Common issues to watch for:
    - **Missing demo data**: Re-run `npx tsx scripts/seed-demo-data.ts` against the production Supabase instance
    - **API route errors**: Check that environment variables are set in Vercel
    - **Type errors in build**: Fix the TypeScript, don't suppress with `ignoreBuildErrors`
    - **UI layout issues**: Check responsive behavior at the demo recording resolution (1920x1080)
    - **Missing pages/routes**: Verify all expected routes exist in the Next.js app directory

    If NO bugs were found in Task 1, skip this task and move directly to the checkpoint.

    After fixes and redeployment, update the QA checklist to mark resolved items.
  </action>
  <verify>
    - All blocker bugs from QA checklist are resolved
    - `npm run build` passes after fixes
    - Production deployment updated with fixes (if any were needed)
    - Re-running failing automated checks now pass
    - QA checklist Bug Log updated with resolution status
  </verify>
  <done>
    All bugs found during QA are fixed and deployed. Production deployment is verified clean. QA checklist shows all critical items passing.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete production deployment with all demo data, QA checklist, and deliverable preparation</what-built>
  <how-to-verify>
    **Production Verification (5 minutes):**
    1. Open the production URL in your browser
    2. Walk through the case queue — verify all 5 cases are visible with correct statuses
    3. Click into each case — verify risk scores, agent results, and narratives load correctly
    4. For Case 1 (Sarah Chen): confirm the "Approved" decision and audit trail are visible
    5. For Case 2 (Viktor Petrov): confirm the sanctions match and "Escalated" decision are visible
    6. For Case 3 (Amara Okafor): confirm the low-confidence flag and "In Review" status
    7. For Case 5 (James Oduya): confirm agents show running/pending states

    **Deliverables Check:**
    8. Open `.planning/deliverables/EXPLANATION.md` — read through and confirm it covers all 4 required topics
    9. Open `.planning/deliverables/DEMO-SCRIPT.md` — review the script timing and confirm it matches what you see in the app

    **Recording:**
    10. Record the demo video following the script in DEMO-SCRIPT.md
    11. Export and verify the video is under 3 minutes

    **Final:**
    12. Confirm all 3 deliverables are ready:
        - Working prototype URL
        - Demo video file
        - 500-word explanation
  </how-to-verify>
  <resume-signal>Type "approved" when all 3 deliverables are ready for submission, or describe any remaining issues</resume-signal>
</task>

</tasks>

<verification>
1. Production deployment passes all QA checklist items
2. No blocker or major bugs remain
3. All 5 demo cases display correctly with expected data
4. Decision workflow functions on decided cases
5. Agent visualization shows correct states for processing case
6. Demo video recorded and under 3 minutes
7. 500-word explanation reviewed and finalized
8. All 3 deliverables confirmed ready for submission
</verification>

<success_criteria>
- Prototype deployed and accessible via public Vercel URL (DELIV-01)
- 3-5 realistic demo cases loaded and displaying correctly (DEPLOY-03)
- 2-3 minute demo video recorded showing full case lifecycle (DELIV-02)
- 500-word explanation covers all required topics (DELIV-03)
- No critical bugs in production deployment
- All submission deliverables ready
</success_criteria>

<output>
After completion, create `.planning/phases/10-demo-polish-deliverables/10-05-SUMMARY.md`

This summary should include:
- Production URL
- Path to demo video file
- Path to 500-word explanation
- QA checklist pass/fail status
- Any known issues or limitations
</output>

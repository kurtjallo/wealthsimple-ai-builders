---
phase: 10-demo-polish-deliverables
plan: 04
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - .planning/deliverables/EXPLANATION.md
autonomous: true

must_haves:
  truths:
    - "Explanation is approximately 500 words (450-550 range)"
    - "Explanation covers all 4 required sections: what human can do, what AI handles, where AI stops, what breaks at scale"
    - "Language is precise and demonstrates deep understanding of the compliance domain"
    - "Specific technical details are included (agent names, sanctions lists, confidence thresholds)"
    - "Regulatory awareness is evident (FINTRAC, PCMLTFA, STR filing requirements)"
  artifacts:
    - path: ".planning/deliverables/EXPLANATION.md"
      provides: "500-word explanation document ready for submission"
      contains: "What the Human Can Do"
  key_links: []
---

<objective>
Write the 500-word explanation document that covers: what the human can now do, what the AI handles, where the AI must stop, and what breaks at scale. This is one of three deliverables for the Wealthsimple AI Builders submission.

Purpose: The explanation demonstrates domain understanding and technical depth. It must convince a Wealthsimple engineer that the builder understands not just the technology but the regulatory and operational context of KYC/AML compliance. This is the "systems thinking" deliverable.

Output: A polished, submission-ready 500-word document.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write the 500-word explanation</name>
  <files>.planning/deliverables/EXPLANATION.md</files>
  <action>
    Create the directory `.planning/deliverables/` if it doesn't exist (may already exist from Plan 03).

    Create `.planning/deliverables/EXPLANATION.md` with the complete explanation. The document should be professional but not corporate — written like a thoughtful engineer explaining their work to other engineers.

    **Structure and content guide:**

    ```markdown
    # KYC/AML Operations Orchestrator

    ## What the Human Can Do

    [~120 words]

    Focus on what the compliance officer can NOW do that they couldn't before, or could only do slowly:
    - Review a complete risk profile with linked evidence in minutes instead of hours
    - See exactly what the AI found and why (transparent reasoning, not black box)
    - Make approve/deny/escalate decisions with full context — every agent's output, confidence levels, and the case narrative
    - File STRs with pre-assembled evidence packages (the AI gathers and organizes, the human decides whether to file)
    - Audit every action: every agent execution, every human decision, timestamped and traceable
    - Focus on judgment calls rather than data gathering — the cognitive work shifts from "find the needle" to "decide what to do about the needle"

    Tone: This section sells the value. What does 5 days -> 3 minutes actually mean for a compliance team?

    ## What the AI Handles

    [~130 words]

    Be specific about the technical capabilities — name the agents, the tools, the data sources:
    - Document processing: Mistral OCR extracts structured data from passports, utility bills, bank statements. Per-field confidence scoring flags uncertain extractions.
    - Sanctions screening: Real OFAC SDN list (11,000+ entries) and UN Security Council sanctions list. Fuzzy name matching with trigram similarity catches transliteration variants. PEP database screening.
    - Identity verification: Cross-references extracted fields across documents. Catches discrepancies (name mismatches, address inconsistencies).
    - Risk scoring: Deterministic weighted formula (documents 20%, identity 25%, sanctions 35%, PEP 20%). No LLM in the scoring math — reproducible and auditable.
    - Case narrative: Gemini generates a plain-English risk assessment with linked evidence, key findings, and a recommended action.
    - Orchestration: All 5 agents run in parallel via Google GenAI SDK. The orchestrator manages timeouts, retries, and failure states.

    Tone: This section demonstrates technical depth. Be precise.

    ## Where the AI Stops

    [~120 words]

    This is the most important section. It demonstrates regulatory awareness:
    - AI never makes final account decisions. Approve/deny/escalate buttons are only available to human officers. This isn't a product choice — it's a regulatory requirement (OSFI E-23, CIRO suitability).
    - STR filing is exclusively human. FINTRAC's "reasonable grounds to suspect" standard requires human judgment. The AI assembles evidence; the officer decides whether grounds exist.
    - Low-confidence results route to manual review. When the OCR confidence drops below threshold (e.g., 62% on a damaged document), the system flags rather than guesses. The officer reviews the original and decides.
    - The AI provides recommendations, not decisions. Critical risk cases auto-surface with escalation suggestions, but the officer always has final authority.

    Tone: This section demonstrates that you understand WHY these boundaries exist, not just that they exist.

    ## What Breaks at Scale

    [~130 words]

    Honest assessment of limitations — this shows production awareness:
    - API rate limits: Gemini and Mistral APIs have rate limits. At 100+ concurrent cases, the orchestrator would need request queuing, backpressure, and retry with exponential backoff. Current implementation handles individual cases.
    - Cost scaling: Processing one case costs ~$0.15-0.30 in API calls (OCR + 5 Gemini calls). At 10,000 cases/day, that's $1,500-3,000/day — viable but requires cost optimization (caching sanctions results, batching OCR, using Flash for low-risk routing).
    - Concurrent processing: The current architecture processes cases independently. At scale, you'd need a job queue (Bull/BullMQ), worker pools, and database connection pooling. Supabase connection limits (~50 for free tier) become the first bottleneck.
    - Sanctions list freshness: OFAC updates their list regularly. Production would need automated refresh (daily cron), change detection, and retroactive re-screening of active cases against new entries.
    - Fuzzy matching accuracy: Trigram similarity works for Latin character sets but struggles with Arabic/Chinese transliterations. Production would need phonetic matching (Soundex, Double Metaphone) and script-aware normalization.

    Tone: This section shows you've thought about production. Be specific about numbers and solutions, not vague about "it might not scale."
    ```

    **Writing guidelines:**
    - Total word count: 450-550 words (aim for 500)
    - No fluff, no filler. Every sentence should convey information.
    - Use concrete numbers: "11,000+ OFAC entries", "94% match score", "$0.15-0.30 per case"
    - Mention specific regulations by name: FINTRAC, PCMLTFA, OSFI E-23, CIRO
    - Reference specific technologies: Google GenAI SDK, Mistral OCR, Supabase, trigram similarity
    - No corporate buzzwords. Write like an engineer explaining to an engineer.
    - The document should read as one continuous piece, not disconnected sections

    **Word count check:** After writing, count the words. If over 550, trim the "What Breaks at Scale" section first (it's the easiest to compress). If under 450, expand the "Where the AI Stops" section (it's the highest-value content for Wealthsimple reviewers).
  </action>
  <verify>
    - `.planning/deliverables/EXPLANATION.md` exists
    - Word count is in the 450-550 range (count manually or with `wc -w`)
    - All 4 sections present: What the Human Can Do, What the AI Handles, Where the AI Stops, What Breaks at Scale
    - Specific numbers referenced: risk score thresholds, OFAC entry count, API costs, confidence percentages
    - Regulatory references included: FINTRAC, PCMLTFA, OSFI E-23
    - No filler/fluff — every sentence conveys concrete information
    - Reads as one cohesive document, not disconnected bullet points
  </verify>
  <done>
    500-word explanation written covering all four required sections with specific technical details, regulatory references, and honest scaling assessment. Ready for submission.
  </done>
</task>

</tasks>

<verification>
1. Document exists at `.planning/deliverables/EXPLANATION.md`
2. Word count is 450-550
3. All 4 sections present and substantive
4. Specific technical details: agent names, API costs, confidence thresholds, match scores
5. Regulatory awareness: FINTRAC, STR filing, human-in-the-loop requirements
6. Scale limitations: rate limits, cost, concurrency, sanctions freshness, fuzzy matching
7. Tone is professional-engineering, not corporate-marketing
</verification>

<success_criteria>
- 500-word explanation covers: what human can do, what AI handles, where AI stops, what breaks at scale (DELIV-03)
- Explanation demonstrates domain understanding of KYC/AML compliance
- Specific technical and regulatory references throughout
- Honest, specific assessment of production scaling challenges
</success_criteria>

<output>
After completion, create `.planning/phases/10-demo-polish-deliverables/10-04-SUMMARY.md`
</output>

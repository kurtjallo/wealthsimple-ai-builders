---
phase: 05-risk-scoring-narrative
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/agents/risk-scorer.ts
  - src/lib/agents/scoring-engine.ts
autonomous: true

must_haves:
  truths:
    - "Risk Scorer agent aggregates signals from Document Processor, Identity Verifier, and Sanctions Screener into a composite risk score"
    - "Composite risk score is 0-100 with weighted formula: documents 20%, identity 25%, sanctions 35%, PEP 20%"
    - "Risk categorized as Low (0-25), Medium (26-50), High (51-75), Critical (76-100)"
    - "Critical risk (76+) triggers auto-escalation with reason"
    - "Agent registers with the orchestrator via registerAgent pattern from Phase 2"
    - "Scoring logic is deterministic and separated from LLM interpretation"
  artifacts:
    - path: "src/lib/agents/scoring-engine.ts"
      provides: "Pure deterministic scoring logic — no LLM dependency"
      exports: ["calculateCompositeRisk", "calculateDocumentRisk", "calculateIdentityRisk", "calculateSanctionsRisk", "getRiskCategory", "DEFAULT_RISK_WEIGHTS"]
    - path: "src/lib/agents/risk-scorer.ts"
      provides: "Risk Scorer agent handler that registers with orchestrator"
      exports: ["riskScorerHandler", "registerRiskScorer"]
  key_links:
    - from: "src/lib/agents/risk-scorer.ts"
      to: "src/lib/agents/base-agent.ts"
      via: "uses runAgent pattern from Phase 2"
      pattern: "import.*from.*base-agent"
    - from: "src/lib/agents/risk-scorer.ts"
      to: "src/lib/agents/orchestrator.ts"
      via: "registers handler with registerAgent"
      pattern: "registerAgent.*risk_scorer"
    - from: "src/lib/agents/risk-scorer.ts"
      to: "src/lib/agents/scoring-engine.ts"
      via: "calls calculateCompositeRisk for deterministic scoring"
      pattern: "import.*calculateCompositeRisk.*from.*scoring-engine"
    - from: "src/lib/agents/scoring-engine.ts"
      to: "src/types/agents.ts"
      via: "uses RiskScorerInput/Output types"
      pattern: "import.*from.*@/types"
---

<objective>
Build the Risk Scorer agent (ORCH-05) — the quantitative backbone that transforms qualitative agent signals into a numeric risk score with confidence levels.

Purpose: The Risk Scorer takes the outputs of Document Processor, Identity Verifier, and Sanctions Screener and produces a composite risk score (0-100), risk level, risk factors breakdown, and auto-escalation flag. This drives the compliance officer's review workflow — high-risk cases surface first.

Output: A pure scoring engine (deterministic, testable, no LLM dependency) and a Risk Scorer agent handler that integrates with the Phase 2 orchestrator via `registerAgent`.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/types/agents.ts (RiskScorerInput, RiskScorerOutput, RiskFactor, AgentResult, DocumentProcessorOutput, IdentityVerifierOutput, SanctionsScreenerOutput)
@src/types/index.ts (RiskLevel — 'low' | 'medium' | 'high' | 'critical')
@src/lib/agents/base-agent.ts (runAgent, AgentHandler)
@src/lib/agents/orchestrator.ts (registerAgent)
@src/lib/agents/agent-config.ts (AGENT_CONFIGS.risk_scorer)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create the deterministic scoring engine</name>
  <files>src/lib/agents/scoring-engine.ts</files>
  <action>
    Create `src/lib/agents/scoring-engine.ts` — a pure TypeScript module with NO Claude SDK or LLM dependencies. This is deterministic scoring logic that can be unit tested without API calls.

    Import types from `@/types` (or relative path if @/ alias not working): `RiskLevel`, `RiskScorerInput`, `DocumentProcessorOutput`, `IdentityVerifierOutput`, `SanctionsScreenerOutput`, `RiskFactor`, `AgentResult`.

    **1. Default risk weights constant:**
    ```typescript
    export const DEFAULT_RISK_WEIGHTS = {
      documents: 0.20,
      identity: 0.25,
      sanctions: 0.35,
      pep: 0.20,  // PEP signals extracted from sanctions result
    } as const;
    ```
    Note: Since there's no separate PEP agent yet (Phase 4 combines PEP with sanctions), the PEP weight is applied to a sub-score derived from the sanctions result. If the sanctions screener returns PEP flags, they contribute to the PEP component. If not, PEP defaults to 0 risk.

    **2. Risk category helper:**
    ```typescript
    export function getRiskCategory(score: number): RiskLevel {
      if (score <= 25) return 'low';
      if (score <= 50) return 'medium';
      if (score <= 75) return 'high';
      return 'critical';
    }
    ```

    **3. Component scoring functions — each returns 0-100:**

    `calculateDocumentRisk(docResult: AgentResult<DocumentProcessorOutput>): { score: number; factors: RiskFactor[] }`
    - If agent failed (docResult.success === false): score = 50 (uncertain = moderate risk), factor: "Document processing failed"
    - Base on document quality scores from `docResult.data.document_quality` — average quality, invert (low quality = high risk)
    - Low confidence (docResult.confidence < 0.5): +20 risk
    - Missing fields (`extracted_fields` with low individual confidence < 0.7): +5 per field, max +30
    - Build RiskFactor[] explaining each contributor
    - Cap at 100

    `calculateIdentityRisk(idResult: AgentResult<IdentityVerifierOutput>): { score: number; factors: RiskFactor[] }`
    - If agent failed: score = 60 (identity failure is more serious)
    - verified === false: +50
    - Each discrepancy: +15 (from idResult.data.discrepancies)
    - Low match confidence (< 0.5 on individual matches): +10 per match
    - Build RiskFactor[] explaining each contributor
    - Cap at 100

    `calculateSanctionsRisk(sanctionsResult: AgentResult<SanctionsScreenerOutput>): { score: number; pepScore: number; factors: RiskFactor[] }`
    - If agent failed: score = 70 (sanctions failure is critical — cannot clear without screening)
    - flagged === true: base +60
    - Each match from sanctionsResult.data.matches:
      - match_score > 0.9: +40 (near certain)
      - match_score > 0.7: +25 (high)
      - match_score > 0.5: +15 (moderate)
    - Multiple matches: additional +10 per match after the first
    - pepScore: Extract from matches where list_name includes "PEP" — use same logic but separate
    - If no PEP data present: pepScore = 0 (no risk if not screened yet)
    - Build RiskFactor[] explaining each contributor
    - Cap at 100

    **4. Main aggregation function:**
    ```typescript
    export function calculateCompositeRisk(input: RiskScorerInput, weights = DEFAULT_RISK_WEIGHTS): {
      risk_score: number;
      risk_level: RiskLevel;
      risk_factors: RiskFactor[];
      requires_manual_review: boolean;
    }
    ```
    - Call each component scoring function
    - compositeScore = round(docRisk * weights.documents + idRisk * weights.identity + sanctionsRisk * weights.sanctions + pepScore * weights.pep)
    - risk_level = getRiskCategory(compositeScore)
    - requires_manual_review = compositeScore > 50 OR any component score > 75 OR any agent failed
    - Merge all RiskFactor[] arrays
    - Return the complete result

    IMPORTANT: All functions must be pure (no side effects, no async, no external calls). These are tested by passing mock AgentResult objects.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - All exports accessible: calculateCompositeRisk, calculateDocumentRisk, calculateIdentityRisk, calculateSanctionsRisk, getRiskCategory, DEFAULT_RISK_WEIGHTS
    - Verify mentally or with quick inline test:
      - All-successful agents with high confidence → low risk score (< 25)
      - Sanctions flagged with match_score 0.95 → critical risk (> 75)
      - All agents failed → high risk (requires_manual_review = true)
      - Weights sum to 1.0 (0.20 + 0.25 + 0.35 + 0.20 = 1.00)
  </verify>
  <done>Pure deterministic scoring engine with 3 component scorers + 1 composite aggregator. Sanctions weighted heaviest (35%). Each component returns scored risk factors. Auto-escalation on critical (76+). No LLM dependency — fully testable with mock data.</done>
</task>

<task type="auto">
  <name>Task 2: Create Risk Scorer agent handler and register with orchestrator</name>
  <files>src/lib/agents/risk-scorer.ts</files>
  <action>
    Create `src/lib/agents/risk-scorer.ts` — the Risk Scorer agent that integrates with the Phase 2 orchestrator.

    Follow the exact same patterns established in Phase 2:
    - Import `runAgent` from `./base-agent`
    - Import `registerAgent` from `./orchestrator`
    - Import `AGENT_CONFIGS` from `./agent-config`
    - Import types from `@/types`

    **Agent handler function:**
    ```typescript
    import Anthropic from '@anthropic-ai/sdk';
    import { RiskScorerInput, RiskScorerOutput, AgentConfig } from '@/types';
    import { calculateCompositeRisk } from './scoring-engine';

    export async function riskScorerHandler(
      input: RiskScorerInput,
      client: Anthropic,
      config: AgentConfig,
    ): Promise<RiskScorerOutput> {
      // Step 1: Use deterministic scoring engine for the numbers
      const scores = calculateCompositeRisk(input);

      // Step 2: Use Claude to generate a human-readable scoring summary
      // that explains the risk factors in compliance language
      const message = await client.messages.create({
        model: config.model,
        max_tokens: config.max_tokens,
        temperature: config.temperature ?? 0,
        messages: [{
          role: 'user',
          content: `You are a KYC/AML risk scoring analyst. Analyze the following risk assessment and write a 2-3 sentence scoring summary suitable for a compliance officer.

Risk Score: ${scores.risk_score}/100 (${scores.risk_level})
Requires Manual Review: ${scores.requires_manual_review}

Risk Factors:
${scores.risk_factors.map(f => `- ${f.factor_name} (weight: ${f.weight}, score: ${f.score}/100): ${f.explanation}`).join('\n')}

Write a concise summary explaining the key risk drivers and whether this case warrants closer scrutiny. Be specific about which factors contributed most.`,
        }],
      });

      const scoringSummary = message.content[0].type === 'text'
        ? message.content[0].text
        : 'Unable to generate scoring summary.';

      return {
        ...scores,
        scoring_summary: scoringSummary,
      };
    }
    ```

    **Registration function:**
    ```typescript
    import { registerAgent } from './orchestrator';

    export function registerRiskScorer(): void {
      registerAgent('risk_scorer', riskScorerHandler);
    }
    ```

    KEY DESIGN: The scoring engine does the math (deterministic, testable), and Claude provides the human-readable interpretation. This separation means:
    - Scores are reproducible and auditable
    - The LLM adds qualitative analysis, not quantitative computation
    - If the LLM call fails, we still have the numeric scores

    The handler signature matches what `runAgent` expects: `(input: TInput, client: Anthropic, config: AgentConfig) => Promise<TOutput>`. The orchestrator calls `runAgent('risk_scorer', input, AGENT_CONFIGS.risk_scorer, getHandler('risk_scorer'))`.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - `riskScorerHandler` signature matches `(input: RiskScorerInput, client: Anthropic, config: AgentConfig) => Promise<RiskScorerOutput>`
    - `registerRiskScorer` calls `registerAgent('risk_scorer', riskScorerHandler)`
    - Handler uses calculateCompositeRisk for deterministic scoring
    - Handler uses Claude API only for the scoring_summary text
    - Return type matches RiskScorerOutput from src/types/agents.ts exactly (risk_score, risk_level, risk_factors, requires_manual_review, scoring_summary)
  </verify>
  <done>Risk Scorer agent handler built. Deterministic scoring via scoring-engine + LLM-generated summary via Claude. Registers with orchestrator via registerAgent. Follows Phase 2 base-agent pattern exactly.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes for all new files
2. Scoring engine correctly implements weighted formula: doc(20%) + identity(25%) + sanctions(35%) + PEP(20%)
3. Risk categories: Low 0-25, Medium 26-50, High 51-75, Critical 76-100
4. Sanctions flagged with high match score → critical risk
5. All agents failed → requires_manual_review = true
6. riskScorerHandler matches Phase 2 handler signature
7. registerRiskScorer wires into orchestrator registry
</verification>

<success_criteria>
- Scoring engine produces deterministic results for all signal combinations (ORCH-05)
- Agent integrates with Phase 2 orchestrator pattern (registerAgent)
- LLM generates qualitative summary while scoring remains deterministic
- Risk factors provide audit trail explaining each score component
- requires_manual_review flags uncertain or high-risk cases for human review
</success_criteria>

<output>
After completion, create `.planning/phases/05-risk-scoring-narrative/05-01-SUMMARY.md`
</output>

---
phase: 05-risk-scoring-narrative
plan: 05
type: execute
wave: 3
depends_on: ["05-02", "05-03"]
files_modified:
  - src/agents/risk-scorer/__tests__/scoring-engine.test.ts
  - src/agents/case-narrator/__tests__/evidence-builder.test.ts
  - src/lib/test-fixtures/risk-signals.ts
autonomous: true

must_haves:
  truths:
    - "Scoring engine produces correct results for all-clear, mixed, and critical signal combinations"
    - "Evidence builder generates correctly formatted evidence IDs and descriptions"
    - "Test fixtures provide reusable mock signals for downstream testing"
    - "Edge cases handled: missing fields, zero confidence, all-maximum scores"
  artifacts:
    - path: "src/lib/test-fixtures/risk-signals.ts"
      provides: "Mock agent signals for testing risk scoring and narration"
      exports: ["clearSignals", "mixedSignals", "criticalSignals", "edgeCaseSignals"]
    - path: "src/agents/risk-scorer/__tests__/scoring-engine.test.ts"
      provides: "Unit tests for scoring engine"
      contains: "describe.*scoring-engine"
    - path: "src/agents/case-narrator/__tests__/evidence-builder.test.ts"
      provides: "Unit tests for evidence builder"
      contains: "describe.*evidence-builder"
  key_links:
    - from: "src/agents/risk-scorer/__tests__/scoring-engine.test.ts"
      to: "src/agents/risk-scorer/scoring-engine.ts"
      via: "imports and tests all scoring functions"
      pattern: "import.*calculateCompositeRisk"
    - from: "src/agents/case-narrator/__tests__/evidence-builder.test.ts"
      to: "src/agents/case-narrator/evidence-builder.ts"
      via: "imports and tests evidence generation"
      pattern: "import.*buildEvidenceLinks"
    - from: "src/lib/test-fixtures/risk-signals.ts"
      to: "src/types/risk.ts"
      via: "fixtures implement signal types"
      pattern: "import.*DocumentSignal.*IdentitySignal.*SanctionsSignal.*PEPSignal"
---

<objective>
Create test fixtures and unit tests for the pure logic modules (scoring engine and evidence builder) to verify correctness across all signal combinations.

Purpose: The scoring engine and evidence builder are deterministic — they can and should be tested without LLM calls. These tests serve as regression protection and validate the scoring math, evidence ID generation, and edge case handling. The test fixtures also become reusable for Phase 8 integration testing.

Output: Test fixtures with 4 signal combinations, unit tests for scoring engine (6 functions), and unit tests for evidence builder (3 functions).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/05-risk-scoring-narrative/05-02-SUMMARY.md
@.planning/phases/05-risk-scoring-narrative/05-03-SUMMARY.md
@src/agents/risk-scorer/scoring-engine.ts
@src/agents/case-narrator/evidence-builder.ts
@src/types/risk.ts
@src/types/narrative.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test fixtures with mock agent signals</name>
  <files>src/lib/test-fixtures/risk-signals.ts</files>
  <action>
Create `src/lib/test-fixtures/risk-signals.ts` — reusable mock data for testing.

**Fixture 1: `clearSignals`** — All-clear, low-risk case
- document: valid passport, 0.95 extraction confidence, 0.92 OCR quality, 8 fields extracted, 0 missing
- identity: verified, 0.97 match confidence, ['name', 'dob', 'address', 'nationality'] verified, 0 discrepancies
- sanctions: clear, no matches, screened lists: ['OFAC_SDN', 'UN_SECURITY_COUNCIL']
- pep: clear, 0.05 confidence
- Expected composite score: ~0-5 (low)

**Fixture 2: `mixedSignals`** — Medium-risk case with some concerns
- document: valid but 0.72 extraction confidence, ocrQuality 0.65, 1 field missing ('address')
- identity: partial verification, 0.68 confidence, 2 of 4 fields verified, 1 discrepancy (address mismatch)
- sanctions: clear, no matches
- pep: potential_pep, 0.45 confidence
- Expected composite score: ~30-45 (medium)

**Fixture 3: `criticalSignals`** — Critical risk, sanctions match
- document: uncertain, 0.55 extraction confidence, ocrQuality 0.45, 3 fields missing
- identity: unverified, 0.30 confidence, 0 fields verified, 2 discrepancies
- sanctions: confirmed_match, one exact match on OFAC_SDN with fuzzyScore 1.0
- pep: confirmed_pep, head_of_state category, 0.92 confidence
- Expected composite score: ~85-100 (critical)

**Fixture 4: `edgeCaseSignals`** — Boundary conditions
- document: invalid, 0.0 extraction confidence, 0.0 OCR quality, 0 fields extracted, 6 fields missing
- identity: failed, 0.0 confidence, empty verified, 5 discrepancies
- sanctions: potential_match, multiple fuzzy matches across lists (one at 0.71, one at 0.86)
- pep: clear, 0.0 confidence
- Expected composite score: ~70-85 (high to critical)

Each fixture exports all four signals as a typed object: `{ document: DocumentSignal, identity: IdentitySignal, sanctions: SanctionsSignal, pep: PEPSignal }`.

Also export a helper `makeCaseId()` that returns a random UUID string for test cases.

All timestamps should use a fixed ISO date string for determinism: `"2026-02-23T12:00:00Z"`.
  </action>
  <verify>
1. `npx tsc --noEmit src/lib/test-fixtures/risk-signals.ts` — compiles
2. All four fixtures conform to their respective signal type interfaces
3. Fixed timestamps for deterministic testing
  </verify>
  <done>Four test fixtures (clear, mixed, critical, edge case) covering the full risk spectrum. Reusable in scoring engine tests, evidence builder tests, and Phase 8 integration tests.</done>
</task>

<task type="auto">
  <name>Task 2: Write unit tests for scoring engine and evidence builder</name>
  <files>src/agents/risk-scorer/__tests__/scoring-engine.test.ts, src/agents/case-narrator/__tests__/evidence-builder.test.ts</files>
  <action>
**Part A: Create `src/agents/risk-scorer/__tests__/scoring-engine.test.ts`**

Use the project's test framework (likely Vitest or Jest — check package.json or Phase 1 setup). Import all scoring functions and test fixtures.

Test suites:

```
describe('calculateDocumentRiskScore', () => {
  test('valid document with high confidence → low score (< 10)')
  test('invalid document → high score (>= 60)')
  test('uncertain document with missing fields → medium score')
  test('score never exceeds 100')
  test('score never goes below 0')
})

describe('calculateIdentityRiskScore', () => {
  test('verified with high confidence → low score (< 10)')
  test('failed verification → high score (>= 70)')
  test('partial with discrepancies → medium score')
  test('each discrepancy adds 15 points')
})

describe('calculateSanctionsRiskScore', () => {
  test('clear → score 0')
  test('confirmed match → score 100')
  test('potential match with exact → score 90')
  test('potential match with high fuzzy (>0.85) → score 75')
  test('potential match with medium fuzzy (>0.7) → score 60')
})

describe('calculatePEPRiskScore', () => {
  test('clear → score 0')
  test('confirmed head of state → score 85')
  test('confirmed family member → score 45')
  test('potential PEP → score 35')
})

describe('calculateConfidence', () => {
  test('high-confidence signals → overall confidence > 0.8')
  test('low-confidence signals → overall confidence < 0.3')
  test('uses correct weights for weighted average')
})

describe('calculateCompositeRisk', () => {
  test('clearSignals → low risk (score 0-25)')
  test('mixedSignals → medium risk (score 26-50)')
  test('criticalSignals → critical risk (score 76-100), autoEscalate true')
  test('edgeCaseSignals → high-to-critical risk')
  test('custom weights are applied correctly')
  test('autoEscalate is true only for critical category')
  test('escalationReason populated when autoEscalate is true')
})
```

**Part B: Create `src/agents/case-narrator/__tests__/evidence-builder.test.ts`**

```
describe('buildEvidenceLinks', () => {
  test('generates DOC-001 evidence link from document signal')
  test('generates ID-VERIFY-001 evidence link from identity signal')
  test('generates SANC-{LIST}-001 evidence link per screened list')
  test('generates PEP-001 evidence link from PEP signal')
  test('evidence descriptions include confidence and status')
  test('confirmed sanctions match description includes "CONFIRMED MATCH"')
})

describe('buildKeyFindings', () => {
  test('generates one finding per agent category (4 total)')
  test('clear signals → all findings have positive or neutral riskImpact')
  test('confirmed sanctions → sanctions finding has critical riskImpact')
  test('each finding references correct evidence link IDs')
})

describe('buildRiskFactors', () => {
  test('clearSignals → empty array (no elevated risks)')
  test('criticalSignals → multiple risk factors with critical severity')
  test('only includes factors for components with score > 25')
  test('each risk factor references relevant evidence links')
})
```

Run tests with: `npx vitest run src/agents/risk-scorer/__tests__/ src/agents/case-narrator/__tests__/` (or equivalent test command for the project).
  </action>
  <verify>
Run the test suites:
```bash
npx vitest run src/agents/risk-scorer/__tests__/scoring-engine.test.ts
npx vitest run src/agents/case-narrator/__tests__/evidence-builder.test.ts
```
All tests must pass. Zero failures.
  </verify>
  <done>Comprehensive unit tests for scoring engine (25+ test cases) and evidence builder (12+ test cases). All pass. Edge cases covered: zero confidence, maximum scores, boundary values, missing fields.</done>
</task>

</tasks>

<verification>
1. All test fixtures compile and match signal type interfaces
2. Scoring engine tests cover all 6 functions with boundary cases
3. Evidence builder tests verify ID format, descriptions, and risk impact mapping
4. All tests pass with zero failures
5. Test fixtures are reusable for Phase 8 integration testing
</verification>

<success_criteria>
- `npx vitest run` (or equivalent) passes all tests with zero failures
- Scoring engine correctly handles: all-clear (low), mixed (medium), confirmed sanctions (critical), edge cases
- Evidence builder generates properly formatted IDs and descriptions
- Test fixtures exported for reuse in integration tests
</success_criteria>

<output>
After completion, create `.planning/phases/05-risk-scoring-narrative/05-05-SUMMARY.md`
</output>

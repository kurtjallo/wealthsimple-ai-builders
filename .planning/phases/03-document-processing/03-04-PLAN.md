---
phase: 03-document-processing
plan: 04
type: execute
wave: 3
depends_on: ["03-01", "03-02", "03-03"]
files_modified:
  - src/lib/agents/document-processor.ts
  - src/lib/agents/types.ts
autonomous: true

must_haves:
  truths:
    - "Document Processor agent accepts a document (file or URL) and returns fully processed results"
    - "Agent orchestrates the full pipeline: upload -> OCR -> extraction -> confidence scoring -> save results"
    - "Agent handles errors gracefully and reports processing failures without crashing"
    - "Agent output follows the structured format expected by the orchestration pipeline"
  artifacts:
    - path: "src/lib/agents/document-processor.ts"
      provides: "Document Processor agent implementation"
      contains: "processDocument"
    - path: "src/lib/agents/types.ts"
      provides: "Agent interface types shared across all agents"
      contains: "AgentResult"
  key_links:
    - from: "src/lib/agents/document-processor.ts"
      to: "src/lib/ocr/mistral-client.ts"
      via: "OCR processing call"
      pattern: "import.*ocrExtractText"
    - from: "src/lib/agents/document-processor.ts"
      to: "src/lib/ocr/structured-extractor.ts"
      via: "structured data extraction call"
      pattern: "import.*extractStructuredData"
    - from: "src/lib/agents/document-processor.ts"
      to: "src/lib/supabase/documents.ts"
      via: "database persistence"
      pattern: "import.*updateDocumentResults"
---

<objective>
Build the Document Processor agent that orchestrates the complete document processing pipeline: OCR -> structured extraction -> confidence scoring -> database persistence. This agent is the bridge between raw document uploads and the orchestration pipeline.

Purpose: The Document Processor is one of the specialized agents in the KYC/AML multi-agent system (ORCH-02). It must produce structured, confidence-scored output that other agents (Identity Verifier, Sanctions Screener) can consume.
Output: A Document Processor agent that takes a document, runs it through OCR and extraction, and returns structured results ready for the orchestration pipeline.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-document-processing/03-01-SUMMARY.md
@.planning/phases/03-document-processing/03-02-SUMMARY.md
@.planning/phases/03-document-processing/03-03-SUMMARY.md
@src/types/documents.ts
@src/lib/ocr/mistral-client.ts
@src/lib/ocr/structured-extractor.ts
@src/lib/supabase/documents.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define shared agent interface types</name>
  <files>src/lib/agents/types.ts</files>
  <action>
    Create `src/lib/agents/types.ts` — shared types for all agents in the system. This establishes the contract that the orchestrator uses to communicate with agents.

    ```typescript
    import { AgentType, AgentRunStatus } from '@/types/index';

    /**
     * Standard result format returned by all agents.
     * The orchestrator expects this shape from every agent.
     */
    export interface AgentResult<T = Record<string, unknown>> {
      agent_type: AgentType;
      status: 'success' | 'failure' | 'partial';
      data: T;
      confidence: number; // 0.0 to 1.0
      processing_time_ms: number;
      warnings: string[];
      error?: string;
    }

    /**
     * Input provided to agents by the orchestrator.
     */
    export interface AgentInput {
      case_id: string;
      [key: string]: unknown;
    }

    /**
     * Agent interface — all agents implement this contract.
     */
    export interface Agent<TInput extends AgentInput = AgentInput, TOutput = Record<string, unknown>> {
      type: AgentType;
      name: string;
      description: string;
      run(input: TInput): Promise<AgentResult<TOutput>>;
    }
    ```

    IMPORTANT: Keep this interface minimal. The Agent interface defines the contract between the orchestrator and specialized agents. Don't add methods that not all agents need. The `run` method is the single entry point.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - `src/lib/agents/types.ts` exports AgentResult, AgentInput, Agent interfaces
    - AgentResult has status, data, confidence, processing_time_ms, warnings, error fields
    - Agent interface has type, name, description, and run() method
  </verify>
  <done>
    Shared agent interface types defined. All agents (document processor, identity verifier, sanctions screener, risk scorer, case narrator) will implement this contract.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Document Processor agent</name>
  <files>src/lib/agents/document-processor.ts</files>
  <action>
    Create `src/lib/agents/document-processor.ts` — the Document Processor agent that orchestrates OCR -> extraction -> persistence:

    ```typescript
    import { Agent, AgentResult, AgentInput } from './types';
    import { ocrExtractText } from '@/lib/ocr/mistral-client';
    import { extractStructuredData } from '@/lib/ocr/structured-extractor';
    import { OcrDocumentInput } from '@/lib/ocr/types';
    import { DocumentProcessingResult, ExtractedDocumentData } from '@/types/documents';
    import { DocumentType } from '@/types/index';
    import {
      updateDocumentStatus,
      updateDocumentResults,
      getDocumentsByCase,
    } from '@/lib/supabase/documents';
    import { getDocumentSignedUrl } from '@/lib/supabase/storage';

    /**
     * Input for the Document Processor agent.
     */
    export interface DocumentProcessorInput extends AgentInput {
      case_id: string;
      document_id: string;
      document_type: DocumentType;
      // Provide ONE of the following:
      file_path?: string; // Supabase Storage path (will generate signed URL)
      file_url?: string; // Direct URL to document
      file_base64?: string; // Base64-encoded document
      mime_type?: string; // Required for base64 input
    }

    /**
     * Output from the Document Processor agent.
     */
    export interface DocumentProcessorOutput {
      document_id: string;
      document_type: DocumentType;
      extracted: ExtractedDocumentData;
      overall_confidence: number;
      ocr_text_length: number;
      page_count: number;
    }

    /**
     * Document Processor Agent.
     *
     * Pipeline: Document -> Mistral OCR -> Claude Extraction -> Confidence Scoring -> Database
     *
     * This agent handles the complete document processing lifecycle:
     * 1. Resolves document source (Storage path -> signed URL, or direct URL/base64)
     * 2. Sends to Mistral OCR for text extraction
     * 3. Sends OCR text to Claude for structured data extraction with confidence
     * 4. Persists results to Supabase
     * 5. Returns structured output for the orchestration pipeline
     */
    export const documentProcessorAgent: Agent<DocumentProcessorInput, DocumentProcessorOutput> = {
      type: 'document_processor',
      name: 'Document Processor',
      description: 'Extracts structured data from documents using Mistral OCR and Claude, with per-field confidence scoring.',

      async run(input: DocumentProcessorInput): Promise<AgentResult<DocumentProcessorOutput>> {
        const startTime = Date.now();
        const warnings: string[] = [];

        try {
          // Mark document as processing
          await updateDocumentStatus(input.document_id, 'processing');

          // Step 1: Resolve document input for OCR
          const ocrInput = await resolveDocumentInput(input);

          // Step 2: Run Mistral OCR
          const ocrResult = await ocrExtractText(ocrInput);

          if (!ocrResult.raw_text || ocrResult.raw_text.trim().length === 0) {
            throw new Error('OCR returned empty text — document may be blank or unreadable');
          }

          if (ocrResult.raw_text.length < 20) {
            warnings.push('Very short OCR output — document may be partially readable');
          }

          // Step 3: Claude structured extraction with confidence scoring
          const extraction = await extractStructuredData(
            ocrResult.raw_text,
            input.document_type
          );

          warnings.push(...extraction.warnings);

          // Step 4: Persist results to database
          const processingTimeMs = Date.now() - startTime;
          await updateDocumentResults(input.document_id, {
            ocr_raw_text: ocrResult.raw_text,
            extracted_data: extraction.extracted as unknown as Record<string, unknown>,
            overall_confidence: extraction.overall_confidence,
            processing_status: 'completed',
            processing_time_ms: processingTimeMs,
            warnings,
          });

          // Step 5: Return structured result
          return {
            agent_type: 'document_processor',
            status: extraction.overall_confidence >= 0.3 ? 'success' : 'partial',
            data: {
              document_id: input.document_id,
              document_type: input.document_type,
              extracted: extraction.extracted,
              overall_confidence: extraction.overall_confidence,
              ocr_text_length: ocrResult.raw_text.length,
              page_count: ocrResult.page_count,
            },
            confidence: extraction.overall_confidence,
            processing_time_ms: Date.now() - startTime,
            warnings,
          };
        } catch (error) {
          const processingTimeMs = Date.now() - startTime;
          const errorMessage = error instanceof Error ? error.message : 'Unknown error during document processing';

          // Persist failure state
          try {
            await updateDocumentResults(input.document_id, {
              ocr_raw_text: '',
              extracted_data: {},
              overall_confidence: 0,
              processing_status: 'failed',
              processing_error: errorMessage,
              processing_time_ms: processingTimeMs,
              warnings,
            });
          } catch {
            // If we can't even update the status, log but don't throw
            warnings.push('Failed to persist error state to database');
          }

          return {
            agent_type: 'document_processor',
            status: 'failure',
            data: {
              document_id: input.document_id,
              document_type: input.document_type,
              extracted: { type: input.document_type, data: {} } as unknown as ExtractedDocumentData,
              overall_confidence: 0,
              ocr_text_length: 0,
              page_count: 0,
            },
            confidence: 0,
            processing_time_ms: processingTimeMs,
            warnings,
            error: errorMessage,
          };
        }
      },
    };

    /**
     * Resolve the document source into an OcrDocumentInput for Mistral.
     */
    async function resolveDocumentInput(input: DocumentProcessorInput): Promise<OcrDocumentInput> {
      if (input.file_url) {
        return { type: 'url', content: input.file_url };
      }

      if (input.file_path) {
        const signedUrl = await getDocumentSignedUrl(input.file_path);
        return { type: 'url', content: signedUrl };
      }

      if (input.file_base64) {
        return {
          type: 'base64',
          content: input.file_base64,
          mime_type: input.mime_type || 'image/jpeg',
        };
      }

      throw new Error('No document source provided — need file_url, file_path, or file_base64');
    }

    /**
     * Convenience: Process all documents for a case.
     * Returns results for each document.
     */
    export async function processAllCaseDocuments(
      caseId: string
    ): Promise<AgentResult<DocumentProcessorOutput>[]> {
      const documents = await getDocumentsByCase(caseId);
      const results: AgentResult<DocumentProcessorOutput>[] = [];

      for (const doc of documents) {
        if (doc.processing_status === 'completed') {
          continue; // Skip already processed documents
        }

        const result = await documentProcessorAgent.run({
          case_id: caseId,
          document_id: doc.id,
          document_type: doc.type as DocumentType,
          file_path: doc.file_path || undefined,
          file_url: doc.file_url || undefined,
        });

        results.push(result);
      }

      return results;
    }
    ```

    IMPORTANT NOTES:
    - The agent catches ALL errors and returns a failure AgentResult rather than throwing. The orchestrator should never get an unhandled exception from an agent.
    - Status is 'success' if confidence >= 0.3, 'partial' if lower (document was processed but results are low quality).
    - `processAllCaseDocuments` is a convenience function for processing all documents in a case sequentially. The orchestrator may call documents in parallel instead.
    - Document resolution supports three sources: Supabase Storage path (most common), direct URL, or base64.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - `src/lib/agents/document-processor.ts` exports documentProcessorAgent and processAllCaseDocuments
    - Agent implements the Agent interface from types.ts
    - Agent.run() never throws — always returns AgentResult with success/failure/partial status
    - Pipeline: resolveInput -> OCR -> extraction -> database -> return
    - Error handling persists failure state to database
  </verify>
  <done>
    Document Processor agent built with complete pipeline: document resolution -> Mistral OCR -> Claude extraction -> confidence scoring -> database persistence. Agent follows the shared Agent interface and handles errors gracefully. Ready for orchestration pipeline integration.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no type errors
2. Agent types define the shared contract (AgentResult, Agent interface)
3. Document Processor agent orchestrates OCR -> extraction -> scoring -> persistence
4. Agent never throws — returns failure status instead
5. Supports three document sources: Storage path, URL, base64
6. processAllCaseDocuments convenience function works for batch processing
</verification>

<success_criteria>
- Document Processor agent fully implements the Agent interface (ORCH-02)
- Agent orchestrates the complete pipeline: OCR -> extraction -> confidence -> save (DOC-01, DOC-02, DOC-04)
- Agent handles errors gracefully and reports failures (never crashes the orchestrator)
- Output structure is consumable by downstream agents (Identity Verifier, Sanctions Screener)
</success_criteria>

<output>
After completion, create `.planning/phases/03-document-processing/03-04-SUMMARY.md`
</output>

---
phase: 08-case-lifecycle-integration
plan: 03
type: execute
wave: 2
depends_on: ["08-02"]
files_modified:
  - src/lib/pipeline/delay-simulator.ts
  - src/lib/pipeline/confidence-router.ts
  - src/lib/pipeline/case-processor.ts
autonomous: true

must_haves:
  truths:
    - "Each agent shows realistic processing delays (2-5 seconds per agent, not instant)"
    - "Total pipeline processing takes 10-20 seconds, showing visible agent activity"
    - "Low-confidence results (any agent confidence < 0.7) automatically flag the case for manual review"
    - "Cases with sanctions matches or identity failures are routed to manual review regardless of score"
    - "Confidence routing logic is deterministic and based on configurable thresholds"
  artifacts:
    - path: "src/lib/pipeline/delay-simulator.ts"
      provides: "Configurable delay injection for realistic agent processing timing"
      exports: ["simulateAgentDelay", "AGENT_DELAY_CONFIG"]
    - path: "src/lib/pipeline/confidence-router.ts"
      provides: "Confidence threshold routing logic for manual review flagging"
      exports: ["evaluateConfidenceRouting", "CONFIDENCE_THRESHOLDS", "ConfidenceRoutingResult"]
    - path: "src/lib/pipeline/case-processor.ts"
      provides: "Updated case processor with delay simulation and confidence routing integrated"
      contains: "processCaseLifecycle"
  key_links:
    - from: "src/lib/pipeline/case-processor.ts"
      to: "src/lib/pipeline/delay-simulator.ts"
      via: "injects delays between pipeline stages"
      pattern: "import.*simulateAgentDelay.*from.*delay-simulator"
    - from: "src/lib/pipeline/case-processor.ts"
      to: "src/lib/pipeline/confidence-router.ts"
      via: "evaluates confidence routing after pipeline completes"
      pattern: "import.*evaluateConfidenceRouting.*from.*confidence-router"
---

<objective>
Add realistic processing delays and confidence-based routing to the case processor. Agents should appear to work (not instant, not slow), and low-confidence results should route to manual review instead of auto-processing.

Purpose: CASE-02 requires "realistic processing delays showing agents working" and CASE-03 requires "confidence thresholds that route uncertain cases to manual review." These are critical for both the demo experience (agents visually working) and the compliance workflow (uncertain results flagged for human attention).
Output: Delay simulator with per-agent timing, confidence router with configurable thresholds, and an updated case processor integrating both.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-case-lifecycle-integration/08-02-SUMMARY.md
@src/lib/pipeline/case-processor.ts
@src/lib/pipeline/progress-emitter.ts
@src/types/pipeline.ts (PipelineState)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create delay simulator and confidence router</name>
  <files>src/lib/pipeline/delay-simulator.ts, src/lib/pipeline/confidence-router.ts</files>
  <action>
    1. Create `src/lib/pipeline/delay-simulator.ts` — configurable delay injection for demo-quality timing:

    ```typescript
    import { PipelineStage } from '@/types';

    /**
     * Per-agent delay configuration (milliseconds).
     * These create the visual effect of agents "working" in the dashboard.
     *
     * Timing strategy for demo:
     * - Document processing: longest (OCR is slow in reality)
     * - Parallel verification: medium (runs concurrently, so wall-clock time is max of both)
     * - Risk scoring: fast (deterministic math)
     * - Narrative generation: medium (LLM generation)
     *
     * Total target: 12-18 seconds for full pipeline. Long enough to see each stage,
     * short enough to not bore the viewer during a 2-3 minute demo video.
     */
    export const AGENT_DELAY_CONFIG: Record<string, { min: number; max: number }> = {
      document_processing: { min: 3000, max: 5000 },
      identity_verifier: { min: 2000, max: 3500 },
      sanctions_screener: { min: 2500, max: 4000 },
      risk_scoring: { min: 1500, max: 2500 },
      narrative_generation: { min: 2000, max: 3500 },
    };

    /**
     * Simulate realistic agent processing delay.
     * Adds a randomized delay within the configured range for the given stage/agent.
     *
     * In production, real agents have natural latency. For the demo,
     * we inject delays to make processing visible in the UI.
     */
    export async function simulateAgentDelay(
      stageOrAgent: string,
      options?: { skipDelay?: boolean }
    ): Promise<number> {
      if (options?.skipDelay) return 0;

      const config = AGENT_DELAY_CONFIG[stageOrAgent];
      if (!config) return 0;

      const delay = config.min + Math.random() * (config.max - config.min);
      await new Promise(resolve => setTimeout(resolve, delay));
      return Math.round(delay);
    }

    /**
     * Calculate the expected total pipeline duration range.
     * Useful for progress bars and time estimates.
     */
    export function getExpectedDuration(): { min: number; max: number } {
      const stages = Object.values(AGENT_DELAY_CONFIG);
      // Parallel verification: take the max of identity + sanctions
      const parallelMin = Math.max(
        AGENT_DELAY_CONFIG.identity_verifier.min,
        AGENT_DELAY_CONFIG.sanctions_screener.min
      );
      const parallelMax = Math.max(
        AGENT_DELAY_CONFIG.identity_verifier.max,
        AGENT_DELAY_CONFIG.sanctions_screener.max
      );

      return {
        min: AGENT_DELAY_CONFIG.document_processing.min + parallelMin +
             AGENT_DELAY_CONFIG.risk_scoring.min + AGENT_DELAY_CONFIG.narrative_generation.min,
        max: AGENT_DELAY_CONFIG.document_processing.max + parallelMax +
             AGENT_DELAY_CONFIG.risk_scoring.max + AGENT_DELAY_CONFIG.narrative_generation.max,
      };
    }
    ```

    2. Create `src/lib/pipeline/confidence-router.ts` — confidence threshold routing for manual review:

    ```typescript
    import { PipelineState } from '@/types';

    /**
     * Confidence thresholds for routing decisions.
     * If any agent's confidence falls below its threshold, the case is flagged for manual review.
     */
    export const CONFIDENCE_THRESHOLDS = {
      // Per-agent confidence thresholds
      document_processor: 0.7,    // OCR accuracy below 70% needs human review
      identity_verifier: 0.8,     // Identity is critical — higher bar
      sanctions_screener: 0.9,    // Sanctions must be highly confident to auto-clear
      risk_scorer: 0.6,           // Risk scoring is aggregated, so lower threshold
      case_narrator: 0.5,         // Narrative quality less critical for routing

      // Global thresholds
      overall_minimum: 0.7,       // Average across all agents must exceed this
      risk_score_escalate: 50,    // Risk score above this -> manual review
      risk_score_deny: 75,        // Risk score above this -> recommend deny
    } as const;

    export interface ConfidenceRoutingResult {
      requires_manual_review: boolean;
      routing_reasons: string[];
      recommended_action: 'auto_review' | 'manual_review' | 'escalate';
      low_confidence_agents: string[];
      overall_confidence: number;
    }

    /**
     * Evaluate pipeline results against confidence thresholds.
     * Determines whether a case should be auto-reviewed or routed to manual review.
     *
     * Manual review triggers:
     * 1. Any agent confidence below its threshold
     * 2. Sanctions match detected (flagged = true)
     * 3. Identity verification failed (verified = false)
     * 4. Risk score above escalation threshold
     * 5. Any agent failed entirely (success = false)
     * 6. Overall average confidence below minimum
     */
    export function evaluateConfidenceRouting(
      pipelineState: PipelineState
    ): ConfidenceRoutingResult {
      const reasons: string[] = [];
      const lowConfidenceAgents: string[] = [];
      const confidences: number[] = [];

      // Check each agent result
      const checks = [
        {
          name: 'document_processor',
          result: pipelineState.document_result,
          threshold: CONFIDENCE_THRESHOLDS.document_processor,
        },
        {
          name: 'identity_verifier',
          result: pipelineState.identity_result,
          threshold: CONFIDENCE_THRESHOLDS.identity_verifier,
        },
        {
          name: 'sanctions_screener',
          result: pipelineState.sanctions_result,
          threshold: CONFIDENCE_THRESHOLDS.sanctions_screener,
        },
        {
          name: 'risk_scorer',
          result: pipelineState.risk_result,
          threshold: CONFIDENCE_THRESHOLDS.risk_scorer,
        },
        {
          name: 'case_narrator',
          result: pipelineState.narrative_result,
          threshold: CONFIDENCE_THRESHOLDS.case_narrator,
        },
      ];

      for (const check of checks) {
        if (!check.result) {
          reasons.push(`${check.name}: no result (agent did not run)`);
          lowConfidenceAgents.push(check.name);
          confidences.push(0);
          continue;
        }

        confidences.push(check.result.confidence);

        // Check for agent failure
        if (!check.result.success) {
          reasons.push(`${check.name}: agent failed — ${check.result.error || 'unknown error'}`);
          lowConfidenceAgents.push(check.name);
          continue;
        }

        // Check confidence threshold
        if (check.result.confidence < check.threshold) {
          reasons.push(
            `${check.name}: confidence ${(check.result.confidence * 100).toFixed(0)}% below threshold ${(check.threshold * 100).toFixed(0)}%`
          );
          lowConfidenceAgents.push(check.name);
        }
      }

      // Check for sanctions match
      const sanctionsData = pipelineState.sanctions_result?.data;
      if (sanctionsData && 'flagged' in sanctionsData && sanctionsData.flagged) {
        reasons.push('Sanctions match detected — requires manual verification');
      }

      // Check for identity verification failure
      const identityData = pipelineState.identity_result?.data;
      if (identityData && 'verified' in identityData && !identityData.verified) {
        reasons.push('Identity verification failed — discrepancies found');
      }

      // Check risk score thresholds
      const riskData = pipelineState.risk_result?.data;
      if (riskData && 'risk_score' in riskData) {
        if (riskData.risk_score >= CONFIDENCE_THRESHOLDS.risk_score_deny) {
          reasons.push(`Risk score ${riskData.risk_score}/100 exceeds deny threshold (${CONFIDENCE_THRESHOLDS.risk_score_deny})`);
        } else if (riskData.risk_score >= CONFIDENCE_THRESHOLDS.risk_score_escalate) {
          reasons.push(`Risk score ${riskData.risk_score}/100 exceeds escalation threshold (${CONFIDENCE_THRESHOLDS.risk_score_escalate})`);
        }
      }

      // Calculate overall confidence
      const overallConfidence = confidences.length > 0
        ? confidences.reduce((a, b) => a + b, 0) / confidences.length
        : 0;

      if (overallConfidence < CONFIDENCE_THRESHOLDS.overall_minimum) {
        reasons.push(
          `Overall confidence ${(overallConfidence * 100).toFixed(0)}% below minimum ${(CONFIDENCE_THRESHOLDS.overall_minimum * 100).toFixed(0)}%`
        );
      }

      // Determine routing
      const requiresManualReview = reasons.length > 0;
      let recommendedAction: ConfidenceRoutingResult['recommended_action'] = 'auto_review';

      if (reasons.length > 0) {
        // Check severity
        const hasSanctionsMatch = sanctionsData && 'flagged' in sanctionsData && sanctionsData.flagged;
        const hasHighRisk = riskData && 'risk_score' in riskData && riskData.risk_score >= CONFIDENCE_THRESHOLDS.risk_score_deny;

        if (hasSanctionsMatch || hasHighRisk) {
          recommendedAction = 'escalate';
        } else {
          recommendedAction = 'manual_review';
        }
      }

      return {
        requires_manual_review: requiresManualReview,
        routing_reasons: reasons,
        recommended_action: recommendedAction,
        low_confidence_agents: lowConfidenceAgents,
        overall_confidence: overallConfidence,
      };
    }
    ```

    IMPORTANT: The confidence router is deterministic — given the same pipeline state, it always produces the same routing result. No LLM calls, no randomness. This is auditable.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - Delay simulator provides configurable per-agent delays (3-5s for document, 2-4s for others)
    - Total expected pipeline duration is 12-18 seconds
    - Confidence router checks all 5 agents against their thresholds
    - Sanctions match always triggers manual review
    - Identity verification failure always triggers manual review
    - Risk score above 50 triggers escalation, above 75 triggers deny recommendation
    - Overall confidence below 70% triggers manual review
    - Router returns deterministic results (no randomness)
  </verify>
  <done>
    Delay simulator provides demo-quality timing (12-18s total pipeline). Confidence router provides deterministic threshold-based routing with per-agent thresholds, sanctions/identity checks, and risk score evaluation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate delays and confidence routing into case processor</name>
  <files>src/lib/pipeline/case-processor.ts</files>
  <action>
    Update `src/lib/pipeline/case-processor.ts` to integrate the delay simulator and confidence router.

    1. Add imports at top of file:
    ```typescript
    import { simulateAgentDelay } from './delay-simulator';
    import { evaluateConfidenceRouting, ConfidenceRoutingResult } from './confidence-router';
    ```

    2. After the orchestrator pipeline completes (after `const pipelineState = await processCase(...)`) and before persisting results, add delay simulation and confidence evaluation:

    **Delay integration — wrap the `processCase` callback to inject delays between stages:**

    Update the `processCase` call to inject delays via the callback:
    ```typescript
    let lastStage: PipelineStage = 'initialized';

    const pipelineState = await processCase(
      { /* ...existing input... */ },
      async (state: PipelineState) => {
        // Inject delay when transitioning to a new stage
        if (state.stage !== lastStage) {
          // Delay happens as the stage starts (simulates agent working)
          if (state.stage !== 'initialized' && state.stage !== 'completed' && state.stage !== 'failed') {
            await simulateAgentDelay(state.stage);
          }
          lastStage = state.stage;
        }

        emitter.emit({
          stage: state.stage,
          status: state.stage === 'failed' ? 'failed' : state.stage === 'completed' ? 'completed' : 'started',
          message: getStageMessage(state.stage, caseData.applicant_name),
        });
      }
    );
    ```

    NOTE: If the `processCase` callback is synchronous-only (doesn't support async callbacks), then add delays AFTER each agent result is persisted instead. Check the orchestrator's callback signature. If the callback is typed as `(state: PipelineState) => void`, wrap delays like this:

    ```typescript
    // Alternative: add delays between agent_runs persistence
    for (const { type, result } of agentResults) {
      if (result) {
        // Simulate processing time for this agent
        const delayMs = await simulateAgentDelay(type);

        emitter.emit({
          stage: pipelineState.stage,
          agent_type: type,
          status: 'started',
          message: `${formatAgentName(type)} processing...`,
        });

        // Small additional delay to show "working" state
        if (delayMs === 0) {
          await simulateAgentDelay(type);
        }

        await supabase.from('agent_runs').insert({ /* ...existing... */ });

        emitter.emit({
          stage: pipelineState.stage,
          agent_type: type,
          status: result.success ? 'completed' : 'failed',
          message: `${formatAgentName(type)} ${result.success ? 'completed' : 'failed'}`,
          confidence: result.confidence,
          duration_ms: result.duration_ms,
        });
      }
    }
    ```

    3. **Confidence routing integration — after pipeline completes, evaluate and update case:**

    After persisting agent results and before the final case update, add:
    ```typescript
    // Evaluate confidence routing
    const routing = evaluateConfidenceRouting(pipelineState);

    // Persist routing result
    await supabase.from('audit_logs').insert({
      case_id: caseId,
      action: 'confidence_routing_evaluated',
      actor_type: 'system',
      actor_id: 'confidence-router',
      details: {
        requires_manual_review: routing.requires_manual_review,
        routing_reasons: routing.routing_reasons,
        recommended_action: routing.recommended_action,
        low_confidence_agents: routing.low_confidence_agents,
        overall_confidence: routing.overall_confidence,
      },
    });

    if (routing.requires_manual_review) {
      emitter.emit({
        stage: pipelineState.stage,
        status: 'completed',
        message: `Case flagged for manual review: ${routing.routing_reasons.length} concern(s) detected`,
      });
    }
    ```

    Then update the case status update to include routing info:
    ```typescript
    // In the case update, use routing result
    await supabase
      .from('cases')
      .update({
        status: 'review',
        risk_score: riskData?.risk_score ?? null,
        risk_level: riskData?.risk_level ?? null,
        narrative: narrativeData?.narrative ?? null,
        // Store routing info in a way the dashboard can use
        updated_at: new Date().toISOString(),
      })
      .eq('id', caseId);
    ```

    4. Add a helper function for formatting agent names:
    ```typescript
    function formatAgentName(agentType: string): string {
      const names: Record<string, string> = {
        document_processor: 'Document Processor',
        identity_verifier: 'Identity Verifier',
        sanctions_screener: 'Sanctions Screener',
        risk_scorer: 'Risk Scorer',
        case_narrator: 'Case Narrator',
      };
      return names[agentType] || agentType;
    }
    ```

    IMPORTANT: The delay simulator adds time BETWEEN stages, not to the agent execution itself. If real agents already take 2+ seconds (Mistral OCR, Claude API calls), you may want to reduce or skip delays. Add a check: if `result.duration_ms > 2000`, skip the simulated delay for that agent.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - Pipeline now takes 12-18 seconds total (not instant)
    - Progress events include timing information
    - Confidence routing evaluated after pipeline completion
    - Routing result persisted to audit trail
    - Cases with low-confidence agents flagged for manual review
    - Cases with sanctions matches routed to manual review
    - Delay skipped for agents that already take 2+ seconds (real API calls)
  </verify>
  <done>
    Case processor updated with realistic delays (12-18s total pipeline) and confidence-based routing. Low-confidence results, sanctions matches, and identity failures automatically flag for manual review. All routing decisions logged to audit trail.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes for all files
2. Full pipeline takes 12-18 seconds (not instant)
3. Each agent stage shows visible processing time (2-5 seconds)
4. Confidence router flags cases when any agent confidence < threshold
5. Sanctions matches always trigger manual review
6. Identity failures always trigger manual review
7. Risk score > 50 triggers escalation recommendation
8. Routing decisions logged to audit_logs table
9. All delays configurable via AGENT_DELAY_CONFIG
10. All thresholds configurable via CONFIDENCE_THRESHOLDS
</verification>

<success_criteria>
- Processing shows realistic delays with agents appearing to work (CASE-02)
- Low-confidence results route to manual review (CASE-03)
- Sanctions matches and identity failures trigger manual review (CASE-03)
- Delay and threshold configuration centralized and easily adjustable
- All routing decisions are auditable
</success_criteria>

<output>
After completion, create `.planning/phases/08-case-lifecycle-integration/08-03-SUMMARY.md`
</output>

---
phase: 08-case-lifecycle-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/api/cases/create/route.ts
  - src/app/api/cases/[id]/process/route.ts
  - src/lib/pipeline/case-processor.ts
  - src/lib/pipeline/progress-emitter.ts
autonomous: true

must_haves:
  truths:
    - "Creating a new case via API returns a case record with status 'pending'"
    - "Triggering processing on a case starts the full agent pipeline (doc processor -> parallel verification -> risk scorer -> narrator)"
    - "Pipeline processing emits progress events for each stage transition so the UI can display real-time status"
    - "Processing results (agent_runs, risk score, narrative) are persisted to Supabase as the pipeline runs"
    - "Case status transitions through: pending -> processing -> review (when complete)"
  artifacts:
    - path: "src/app/api/cases/create/route.ts"
      provides: "POST endpoint to create a new KYC case with applicant info"
      exports: ["POST"]
    - path: "src/app/api/cases/[id]/process/route.ts"
      provides: "POST endpoint to trigger full pipeline processing for a case"
      exports: ["POST"]
    - path: "src/lib/pipeline/case-processor.ts"
      provides: "Orchestrates full case processing: loads documents, runs agents, persists results"
      exports: ["processCaseLifecycle"]
    - path: "src/lib/pipeline/progress-emitter.ts"
      provides: "Event emitter for pipeline progress updates consumed by SSE endpoint"
      exports: ["ProgressEmitter", "createProgressEmitter"]
  key_links:
    - from: "src/app/api/cases/[id]/process/route.ts"
      to: "src/lib/pipeline/case-processor.ts"
      via: "calls processCaseLifecycle to run the full pipeline"
      pattern: "import.*processCaseLifecycle.*from.*case-processor"
    - from: "src/lib/pipeline/case-processor.ts"
      to: "src/lib/agents/orchestrator.ts"
      via: "calls processCase from Phase 2 orchestrator"
      pattern: "import.*processCase.*from.*orchestrator"
    - from: "src/lib/pipeline/case-processor.ts"
      to: "src/lib/agents/register-all.ts"
      via: "registers all real agents before processing"
      pattern: "import.*registerAllAgents"
    - from: "src/lib/pipeline/case-processor.ts"
      to: "src/lib/supabase/server.ts"
      via: "persists agent_runs and updates case status"
      pattern: "import.*createServerSupabaseClient"
---

<objective>
Build the case creation and processing pipeline trigger — the control plane that connects document upload (Plan 01) to the agent orchestrator (Phase 2). Creating a case, then triggering processing, runs the full agent pipeline and persists all results.

Purpose: This is the backbone of CASE-01. The user creates a case, uploads documents (Plan 01), then triggers processing. The pipeline runs all agents in the correct order (document processing -> parallel identity/sanctions -> risk scoring -> narrative), persisting each result to Supabase. Progress events enable real-time UI updates (Phase 7).
Output: Case creation API, processing trigger API, case processor that bridges the lifecycle to the orchestrator, and a progress emitter for real-time updates.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/types/index.ts (Case, CaseStatus, AgentType, AgentRunStatus)
@src/types/pipeline.ts (PipelineState, PipelineStage)
@src/lib/agents/orchestrator.ts (processCase, registerAgent)
@src/lib/agents/register-all.ts (registerAllAgents)
@src/lib/supabase/server.ts (createServerSupabaseClient)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create case creation API route and progress emitter</name>
  <files>src/app/api/cases/create/route.ts, src/lib/pipeline/progress-emitter.ts</files>
  <action>
    1. Create `src/app/api/cases/create/route.ts` — POST endpoint to create a new KYC case:

    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { createServerSupabaseClient } from '@/lib/supabase/server';
    import { randomUUID } from 'crypto';

    interface CreateCaseRequest {
      applicant_name: string;
      applicant_email: string;
    }

    export async function POST(request: NextRequest) {
      try {
        const body: CreateCaseRequest = await request.json();

        if (!body.applicant_name || !body.applicant_email) {
          return NextResponse.json(
            { error: 'applicant_name and applicant_email are required' },
            { status: 400 }
          );
        }

        const supabase = createServerSupabaseClient();
        const caseId = randomUUID();

        const { data: newCase, error } = await supabase
          .from('cases')
          .insert({
            id: caseId,
            applicant_name: body.applicant_name,
            applicant_email: body.applicant_email,
            status: 'pending',
          })
          .select()
          .single();

        if (error) {
          throw new Error(`Failed to create case: ${error.message}`);
        }

        // Log case creation to audit trail
        await supabase.from('audit_logs').insert({
          case_id: caseId,
          action: 'case_created',
          actor_type: 'officer',
          actor_id: 'demo-officer',
          details: {
            applicant_name: body.applicant_name,
            applicant_email: body.applicant_email,
          },
        });

        return NextResponse.json({ case: newCase }, { status: 201 });
      } catch (error) {
        return NextResponse.json(
          { error: error instanceof Error ? error.message : 'Failed to create case' },
          { status: 500 }
        );
      }
    }
    ```

    2. Create `src/lib/pipeline/progress-emitter.ts` — a simple event system for pipeline progress:

    ```typescript
    import { PipelineStage } from '@/types';

    export interface ProgressEvent {
      case_id: string;
      stage: PipelineStage;
      agent_type?: string;
      status: 'started' | 'completed' | 'failed';
      message: string;
      confidence?: number;
      timestamp: string;
      duration_ms?: number;
    }

    type ProgressListener = (event: ProgressEvent) => void;

    /**
     * Simple event emitter for pipeline progress.
     * Used to bridge the orchestrator's state callbacks to SSE/polling endpoints.
     */
    export class ProgressEmitter {
      private listeners: ProgressListener[] = [];
      private events: ProgressEvent[] = [];
      readonly caseId: string;

      constructor(caseId: string) {
        this.caseId = caseId;
      }

      on(listener: ProgressListener): () => void {
        this.listeners.push(listener);
        return () => {
          this.listeners = this.listeners.filter(l => l !== listener);
        };
      }

      emit(event: Omit<ProgressEvent, 'case_id' | 'timestamp'>): void {
        const fullEvent: ProgressEvent = {
          ...event,
          case_id: this.caseId,
          timestamp: new Date().toISOString(),
        };
        this.events.push(fullEvent);
        this.listeners.forEach(l => l(fullEvent));
      }

      getEvents(): ProgressEvent[] {
        return [...this.events];
      }
    }

    // In-memory store of active pipelines (single-server demo)
    const activePipelines = new Map<string, ProgressEmitter>();

    export function createProgressEmitter(caseId: string): ProgressEmitter {
      const emitter = new ProgressEmitter(caseId);
      activePipelines.set(caseId, emitter);
      return emitter;
    }

    export function getProgressEmitter(caseId: string): ProgressEmitter | undefined {
      return activePipelines.get(caseId);
    }

    export function removeProgressEmitter(caseId: string): void {
      activePipelines.delete(caseId);
    }
    ```

    IMPORTANT: The in-memory progress store is fine for this single-server demo. For production, you'd use Redis pub/sub or Supabase Realtime. But for the demo video with one user, this works perfectly.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - Case creation endpoint validates required fields, creates case with 'pending' status, logs to audit trail
    - ProgressEmitter supports on/emit/getEvents pattern
    - In-memory store tracks active pipelines by case_id
  </verify>
  <done>
    Case creation API creates cases with audit logging. Progress emitter provides event-based pipeline status updates for real-time UI consumption.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create case processor and processing trigger API route</name>
  <files>src/lib/pipeline/case-processor.ts, src/app/api/cases/[id]/process/route.ts</files>
  <action>
    1. Create `src/lib/pipeline/case-processor.ts` — the bridge between the case lifecycle and the Phase 2 orchestrator:

    ```typescript
    import { createServerSupabaseClient } from '@/lib/supabase/server';
    import { processCase } from '@/lib/agents/orchestrator';
    import { registerAllAgents } from '@/lib/agents/register-all';
    import { PipelineState, PipelineStage } from '@/types';
    import { createProgressEmitter, removeProgressEmitter } from './progress-emitter';

    // Ensure agents are registered
    registerAllAgents();

    /**
     * Process a case through the full agent pipeline.
     * This is the main entry point for the case lifecycle.
     *
     * Steps:
     * 1. Load case and documents from Supabase
     * 2. Update case status to 'processing'
     * 3. Run the orchestrator pipeline with progress callbacks
     * 4. Persist each agent result to agent_runs table
     * 5. Update case with final risk score, narrative, status
     * 6. Return the final pipeline state
     */
    export async function processCaseLifecycle(caseId: string): Promise<PipelineState> {
      const supabase = createServerSupabaseClient();
      const emitter = createProgressEmitter(caseId);

      try {
        // 1. Load case data
        const { data: caseData, error: caseError } = await supabase
          .from('cases')
          .select('*')
          .eq('id', caseId)
          .single();

        if (caseError || !caseData) {
          throw new Error(`Case not found: ${caseId}`);
        }

        // 2. Load documents for this case
        const { data: documents, error: docsError } = await supabase
          .from('documents')
          .select('*')
          .eq('case_id', caseId);

        if (docsError || !documents || documents.length === 0) {
          throw new Error('No documents found for this case. Upload documents before processing.');
        }

        // 3. Update case status to processing
        await supabase
          .from('cases')
          .update({ status: 'processing', updated_at: new Date().toISOString() })
          .eq('id', caseId);

        emitter.emit({
          stage: 'initialized',
          status: 'started',
          message: `Starting case processing for ${caseData.applicant_name} with ${documents.length} document(s)`,
        });

        // Log processing start to audit trail
        await supabase.from('audit_logs').insert({
          case_id: caseId,
          action: 'processing_started',
          actor_type: 'system',
          actor_id: 'orchestrator',
          details: { document_count: documents.length },
        });

        // 4. Run the orchestrator pipeline
        const pipelineState = await processCase(
          {
            case_id: caseId,
            documents: documents.map(d => ({
              id: d.id,
              file_url: d.file_url || d.file_path,
              file_name: d.file_name,
              type: d.type,
            })),
            applicant_name: caseData.applicant_name,
            applicant_email: caseData.applicant_email,
          },
          // Progress callback — emit events for each stage transition
          (state: PipelineState) => {
            emitter.emit({
              stage: state.stage,
              status: state.stage === 'failed' ? 'failed' : state.stage === 'completed' ? 'completed' : 'started',
              message: getStageMessage(state.stage, caseData.applicant_name),
            });
          }
        );

        // 5. Persist agent results to agent_runs table
        const agentResults = [
          { type: 'document_processor', result: pipelineState.document_result },
          { type: 'identity_verifier', result: pipelineState.identity_result },
          { type: 'sanctions_screener', result: pipelineState.sanctions_result },
          { type: 'risk_scorer', result: pipelineState.risk_result },
          { type: 'case_narrator', result: pipelineState.narrative_result },
        ];

        for (const { type, result } of agentResults) {
          if (result) {
            await supabase.from('agent_runs').insert({
              case_id: caseId,
              agent_type: type,
              status: result.success ? 'completed' : 'failed',
              started_at: new Date(Date.now() - result.duration_ms).toISOString(),
              completed_at: new Date().toISOString(),
              input: {},
              output: result.data,
              confidence: result.confidence,
              error: result.error,
            });

            emitter.emit({
              stage: pipelineState.stage,
              agent_type: type,
              status: result.success ? 'completed' : 'failed',
              message: `${type} ${result.success ? 'completed' : 'failed'}`,
              confidence: result.confidence,
              duration_ms: result.duration_ms,
            });
          }
        }

        // 6. Update case with final results
        if (pipelineState.stage === 'completed') {
          const riskData = pipelineState.risk_result?.data;
          const narrativeData = pipelineState.narrative_result?.data;

          await supabase
            .from('cases')
            .update({
              status: riskData?.requires_manual_review ? 'review' : 'review',
              risk_score: riskData?.risk_score ?? null,
              risk_level: riskData?.risk_level ?? null,
              narrative: narrativeData?.narrative ?? null,
              updated_at: new Date().toISOString(),
            })
            .eq('id', caseId);

          emitter.emit({
            stage: 'completed',
            status: 'completed',
            message: `Case processing complete. Risk: ${riskData?.risk_level?.toUpperCase() ?? 'UNKNOWN'} (${riskData?.risk_score ?? 0}/100). Ready for review.`,
            confidence: riskData?.risk_score ? riskData.risk_score / 100 : 0,
          });

          // Audit log
          await supabase.from('audit_logs').insert({
            case_id: caseId,
            action: 'processing_completed',
            actor_type: 'system',
            actor_id: 'orchestrator',
            details: {
              risk_score: riskData?.risk_score,
              risk_level: riskData?.risk_level,
              requires_manual_review: riskData?.requires_manual_review,
              recommended_action: narrativeData?.recommended_action,
            },
          });
        } else {
          // Pipeline failed
          await supabase
            .from('cases')
            .update({
              status: 'review', // Even on failure, route to review so officer sees the errors
              updated_at: new Date().toISOString(),
            })
            .eq('id', caseId);

          emitter.emit({
            stage: 'failed',
            status: 'failed',
            message: `Processing encountered errors. ${pipelineState.errors.length} error(s). Case routed to manual review.`,
          });
        }

        return pipelineState;

      } finally {
        // Clean up emitter after a delay (let SSE clients catch up)
        setTimeout(() => removeProgressEmitter(caseId), 30000);
      }
    }

    function getStageMessage(stage: PipelineStage, applicantName: string): string {
      switch (stage) {
        case 'initialized':
          return `Initializing case processing for ${applicantName}...`;
        case 'document_processing':
          return 'Processing documents with OCR and extracting structured data...';
        case 'parallel_verification':
          return 'Running identity verification and sanctions screening in parallel...';
        case 'risk_scoring':
          return 'Calculating composite risk score from all agent signals...';
        case 'narrative_generation':
          return 'Generating case narrative and risk assessment...';
        case 'completed':
          return 'All agents completed. Case ready for officer review.';
        case 'failed':
          return 'Processing encountered errors. Routing to manual review.';
        default:
          return `Pipeline stage: ${stage}`;
      }
    }
    ```

    2. Create `src/app/api/cases/[id]/process/route.ts` — POST endpoint to trigger processing:

    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { createServerSupabaseClient } from '@/lib/supabase/server';
    import { processCaseLifecycle } from '@/lib/pipeline/case-processor';

    export async function POST(
      request: NextRequest,
      { params }: { params: Promise<{ id: string }> }
    ) {
      const { id: caseId } = await params;

      try {
        const supabase = createServerSupabaseClient();

        // Verify case exists and is in processable state
        const { data: caseData, error: caseError } = await supabase
          .from('cases')
          .select('id, status')
          .eq('id', caseId)
          .single();

        if (caseError || !caseData) {
          return NextResponse.json({ error: 'Case not found' }, { status: 404 });
        }

        if (caseData.status === 'processing') {
          return NextResponse.json(
            { error: 'Case is already being processed' },
            { status: 409 }
          );
        }

        if (['approved', 'denied'].includes(caseData.status)) {
          return NextResponse.json(
            { error: `Case has already been ${caseData.status}. Cannot reprocess.` },
            { status: 400 }
          );
        }

        // Verify documents exist
        const { count } = await supabase
          .from('documents')
          .select('*', { count: 'exact', head: true })
          .eq('case_id', caseId);

        if (!count || count === 0) {
          return NextResponse.json(
            { error: 'No documents uploaded. Upload at least one document before processing.' },
            { status: 400 }
          );
        }

        // Start processing (runs asynchronously)
        // We return immediately and the client polls for progress
        const processingPromise = processCaseLifecycle(caseId);

        // For the demo, we can wait for completion to return the full result.
        // In production, this would return 202 Accepted and process asynchronously.
        const pipelineState = await processingPromise;

        return NextResponse.json({
          success: pipelineState.stage === 'completed',
          pipeline_state: pipelineState,
          message: pipelineState.stage === 'completed'
            ? 'Case processed successfully. Ready for officer review.'
            : `Processing completed with status: ${pipelineState.stage}`,
        });

      } catch (error) {
        return NextResponse.json(
          { error: error instanceof Error ? error.message : 'Processing failed' },
          { status: 500 }
        );
      }
    }
    ```

    IMPORTANT NOTES:
    - `processCaseLifecycle` is synchronous (waits for pipeline to complete) for the demo. In production, you'd return 202 Accepted and let the client poll/SSE for progress.
    - The case processor registers agents at module load via `registerAllAgents()`. This ensures real agents (from Phases 3-5) are used instead of stubs when available.
    - Status transitions: pending -> processing -> review. Even failed pipelines route to 'review' so the officer can see what happened.
    - All results are persisted to `agent_runs` table for the audit trail (Phase 9).
    - Use Next.js 15 dynamic route params convention — `params` is a Promise.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - Case processor loads case and documents from Supabase
    - Pipeline runs through all stages with progress emissions
    - Each agent result persisted to agent_runs table
    - Case updated with risk_score, risk_level, narrative, and status='review'
    - Processing API validates: case exists, not already processing, has documents
    - Audit trail logged for processing start and completion
    - Test with curl:
      ```bash
      curl -X POST http://localhost:3000/api/cases/{case_id}/process
      ```
      Expected: 200 with pipeline_state showing all agent results
  </verify>
  <done>
    Case processor bridges the lifecycle to the orchestrator. Processing API triggers the full pipeline, persists all agent results, updates case status, and emits progress events. The golden path from case creation through processing is now wired end-to-end.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes for all files
2. POST /api/cases/create creates a case with status 'pending' and audit log
3. POST /api/cases/[id]/process triggers full pipeline and returns completed state
4. Pipeline transitions: initialized -> document_processing -> parallel_verification -> risk_scoring -> narrative_generation -> completed
5. All 5 agent results persisted to agent_runs table
6. Case record updated with risk_score, risk_level, narrative
7. Progress events emitted for each stage transition
8. Audit trail logged at start and completion
9. Guards: no reprocessing approved/denied cases, no processing without documents
</verification>

<success_criteria>
- Full pipeline runs from case creation to completion (CASE-01 backbone)
- All agent results persisted for audit trail
- Case status transitions correctly through the lifecycle
- Progress events available for real-time UI updates
- Error states route to manual review (never silently fail)
</success_criteria>

<output>
After completion, create `.planning/phases/08-case-lifecycle-integration/08-02-SUMMARY.md`
</output>

---
phase: 09-regulatory-audit-trail
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/audit/guards.ts
  - src/app/api/cases/[id]/decide/route.ts
  - src/app/api/cases/[id]/str/route.ts
autonomous: true

must_haves:
  truths:
    - "AI cannot make final account decisions — approve/deny/escalate API endpoints validate that the caller is a human officer"
    - "API decision endpoint rejects requests without officer_id and justification with a 400 error"
    - "STR filing endpoint is exclusively human-only — rejects any non-officer request and provides FINTRAC regulatory context"
    - "STR workflow returns regulatory context explaining FINTRAC requirements for suspicious transaction reporting"
    - "All decisions logged through the audit logging system from Plan 01"
  artifacts:
    - path: "src/lib/audit/guards.ts"
      provides: "Server-side validation functions that enforce human-in-the-loop at decision points"
      exports: ["validateHumanDecision", "validateSTRAuthority", "DecisionValidationError"]
    - path: "src/app/api/cases/[id]/decide/route.ts"
      provides: "POST endpoint for officer decisions with mandatory human-in-the-loop validation"
      exports: ["POST"]
    - path: "src/app/api/cases/[id]/str/route.ts"
      provides: "POST endpoint for STR filing referral — exclusively human, with FINTRAC context"
      exports: ["POST"]
  key_links:
    - from: "src/lib/audit/guards.ts"
      to: "src/lib/audit/types.ts"
      via: "uses HumanDecisionAuditPayload for validation"
      pattern: "import.*from.*audit/types"
    - from: "src/app/api/cases/[id]/decide/route.ts"
      to: "src/lib/audit/guards.ts"
      via: "calls validateHumanDecision before processing"
      pattern: "import.*validateHumanDecision.*from.*audit/guards"
    - from: "src/app/api/cases/[id]/decide/route.ts"
      to: "src/lib/audit/logger.ts"
      via: "calls logHumanDecision after successful decision"
      pattern: "import.*logHumanDecision.*from.*audit/logger"
    - from: "src/app/api/cases/[id]/str/route.ts"
      to: "src/lib/audit/guards.ts"
      via: "calls validateSTRAuthority before processing"
      pattern: "import.*validateSTRAuthority.*from.*audit/guards"
    - from: "src/app/api/cases/[id]/str/route.ts"
      to: "src/lib/supabase/server.ts"
      via: "reads/writes case data"
      pattern: "import.*createServerSupabaseClient.*from.*supabase/server"
---

<objective>
Implement human-in-the-loop enforcement at the API level and create the STR (Suspicious Transaction Report) filing workflow. This ensures AI can never make final account decisions — all decision endpoints require a human officer_id and justification, validated server-side. The STR workflow is marked as exclusively human per FINTRAC requirements.

Purpose: REG-01 (human-in-the-loop), REG-02 (AI never makes final decisions), and REG-03 (STR exclusively human) are the core regulatory requirements. This plan enforces them at the API layer — the last line of defense before data reaches the database. Even if the UI has a bug, the server rejects unauthorized decisions.

Output: Server-side guard functions, a hardened decision endpoint, and an STR filing workflow with FINTRAC regulatory context.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/types/index.ts (Case, CaseStatus, DecisionType, ActorType)
@src/lib/supabase/server.ts (createServerSupabaseClient)
@src/lib/audit/types.ts (HumanDecisionAuditPayload — from Plan 01)
@src/lib/audit/logger.ts (logHumanDecision, logSystemEvent, AUDIT_ACTIONS — from Plan 01)
@src/lib/audit/constants.ts (AUDIT_ACTIONS — from Plan 01)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create server-side human-in-the-loop guard functions</name>
  <files>src/lib/audit/guards.ts</files>
  <action>
    Create `src/lib/audit/guards.ts` — server-side validation functions that enforce human authority at decision points. These are called by API endpoints BEFORE any decision is processed.

    ```typescript
    /**
     * Human-in-the-loop guard functions for regulatory compliance.
     *
     * FINTRAC/PCMLTFA requires that ALL compliance decisions are made by human officers.
     * AI agents may recommend but NEVER decide. These guards enforce that at the API layer.
     *
     * REG-01: Human-in-the-loop at all decision points
     * REG-02: AI never makes final account decisions
     * REG-03: STR filing remains exclusively human
     */

    export class DecisionValidationError extends Error {
      public readonly statusCode: number;
      public readonly field?: string;

      constructor(message: string, statusCode: number = 400, field?: string) {
        super(message);
        this.name = 'DecisionValidationError';
        this.statusCode = statusCode;
        this.field = field;
      }
    }

    export interface DecisionRequest {
      officer_id?: string;
      officer_name?: string;
      decision?: string;
      justification?: string;
    }

    export interface STRReferralRequest {
      officer_id?: string;
      officer_name?: string;
      reason?: string;
      suspicious_indicators?: string[];
    }

    const VALID_DECISIONS = ['approved', 'denied', 'escalated'] as const;
    const MIN_JUSTIFICATION_LENGTH = 10; // Require meaningful justification, not "ok"

    /**
     * Validate that a decision request comes from a human officer with proper justification.
     *
     * Checks:
     * 1. officer_id is present and non-empty (proves human identity)
     * 2. decision is one of: approved, denied, escalated
     * 3. justification is present and at least 10 characters (meaningful text)
     *
     * Throws DecisionValidationError with specific field and message on failure.
     */
    export function validateHumanDecision(request: DecisionRequest): {
      officer_id: string;
      decision: 'approved' | 'denied' | 'escalated';
      justification: string;
      officer_name?: string;
    } {
      // Check 1: Human officer identification
      if (!request.officer_id || request.officer_id.trim().length === 0) {
        throw new DecisionValidationError(
          'REG-02 violation: All compliance decisions require a human officer. Provide officer_id to identify the decision-maker.',
          400,
          'officer_id',
        );
      }

      // Block any actor that looks like an AI/agent/system
      const suspiciousActors = ['system', 'agent', 'ai', 'bot', 'auto', 'orchestrator'];
      if (suspiciousActors.some(s => request.officer_id!.toLowerCase().includes(s))) {
        throw new DecisionValidationError(
          'REG-02 violation: AI agents and automated systems cannot make compliance decisions. Only human officers may approve, deny, or escalate cases.',
          403,
          'officer_id',
        );
      }

      // Check 2: Valid decision type
      if (!request.decision || !VALID_DECISIONS.includes(request.decision as any)) {
        throw new DecisionValidationError(
          `Invalid decision. Must be one of: ${VALID_DECISIONS.join(', ')}. AI recommendations are advisory only — the human officer selects the final decision.`,
          400,
          'decision',
        );
      }

      // Check 3: Meaningful justification
      if (!request.justification || request.justification.trim().length < MIN_JUSTIFICATION_LENGTH) {
        throw new DecisionValidationError(
          `REG-04 violation: FINTRAC requires documented justification for all compliance decisions. Provide at least ${MIN_JUSTIFICATION_LENGTH} characters explaining the reasoning.`,
          400,
          'justification',
        );
      }

      return {
        officer_id: request.officer_id.trim(),
        decision: request.decision as 'approved' | 'denied' | 'escalated',
        justification: request.justification.trim(),
        officer_name: request.officer_name?.trim(),
      };
    }

    /**
     * Validate that an STR filing referral comes from a human officer.
     *
     * FINTRAC requirement: STR filing is EXCLUSIVELY human. Under the Proceeds of Crime
     * (Money Laundering) and Terrorist Financing Act (PCMLTFA), only a designated human
     * officer can determine "reasonable grounds to suspect" money laundering or terrorist
     * financing and file an STR with FINTRAC.
     *
     * AI may flag suspicious patterns, but the decision to file is always human.
     *
     * Throws DecisionValidationError with specific field and message on failure.
     */
    export function validateSTRAuthority(request: STRReferralRequest): {
      officer_id: string;
      officer_name?: string;
      reason: string;
      suspicious_indicators: string[];
    } {
      // Check 1: Human officer identification (same as decision)
      if (!request.officer_id || request.officer_id.trim().length === 0) {
        throw new DecisionValidationError(
          'REG-03 violation: STR filing is exclusively a human responsibility under FINTRAC/PCMLTFA. A designated compliance officer must initiate all STR referrals.',
          400,
          'officer_id',
        );
      }

      // Block automated actors
      const suspiciousActors = ['system', 'agent', 'ai', 'bot', 'auto', 'orchestrator'];
      if (suspiciousActors.some(s => request.officer_id!.toLowerCase().includes(s))) {
        throw new DecisionValidationError(
          'REG-03 violation: AI systems CANNOT file or initiate Suspicious Transaction Reports. Under PCMLTFA, only a designated human compliance officer may determine "reasonable grounds to suspect" and file an STR with FINTRAC.',
          403,
          'officer_id',
        );
      }

      // Check 2: Reason for STR referral
      if (!request.reason || request.reason.trim().length < 20) {
        throw new DecisionValidationError(
          'FINTRAC requires detailed reasoning for STR referrals. Provide at least 20 characters explaining the suspicious indicators and why this case warrants an STR.',
          400,
          'reason',
        );
      }

      return {
        officer_id: request.officer_id.trim(),
        officer_name: request.officer_name?.trim(),
        reason: request.reason.trim(),
        suspicious_indicators: Array.isArray(request.suspicious_indicators)
          ? request.suspicious_indicators.filter(s => typeof s === 'string' && s.trim().length > 0)
          : [],
      };
    }
    ```

    KEY DESIGN: These guard functions are pure validation — they throw typed errors or return validated data. The API endpoints catch `DecisionValidationError` and return the appropriate HTTP status. This separation means guards can be tested independently.
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - guards.ts exports: validateHumanDecision, validateSTRAuthority, DecisionValidationError
    - validateHumanDecision rejects: missing officer_id, AI-like actor_id, invalid decision, short justification
    - validateHumanDecision returns validated + trimmed data on success
    - validateSTRAuthority rejects: missing officer_id, AI-like actor_id, short reason
    - validateSTRAuthority returns validated data on success
    - Error messages reference specific regulatory requirements (REG-02, REG-03, REG-04)
  </verify>
  <done>Server-side guard functions enforce human-in-the-loop at all decision points. Rejects AI/agent actors, requires meaningful justification, blocks STR filing by non-human actors. Error messages cite specific FINTRAC/PCMLTFA regulatory requirements.</done>
</task>

<task type="auto">
  <name>Task 2: Create decision and STR filing API endpoints</name>
  <files>src/app/api/cases/[id]/decide/route.ts, src/app/api/cases/[id]/str/route.ts</files>
  <action>
    **1. Create `src/app/api/cases/[id]/decide/route.ts`:**

    This is the primary decision endpoint. It replaces or enhances any existing decision endpoint from Phase 6/8 with full regulatory compliance.

    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { createServerSupabaseClient } from '@/lib/supabase/server';
    import { validateHumanDecision, DecisionValidationError } from '@/lib/audit/guards';
    import { logHumanDecision, logSystemEvent, AUDIT_ACTIONS } from '@/lib/audit/logger';
    import { CaseStatus } from '@/types';

    export async function POST(
      request: NextRequest,
      { params }: { params: Promise<{ id: string }> }
    ) {
      const { id: caseId } = await params;

      try {
        // Parse request body
        const body = await request.json();

        // REGULATORY GUARD: Validate human-in-the-loop (REG-01, REG-02)
        // This throws DecisionValidationError if validation fails
        const validated = validateHumanDecision(body);

        const supabase = createServerSupabaseClient();

        // Load current case state
        const { data: caseData, error: caseError } = await supabase
          .from('cases')
          .select('*')
          .eq('id', caseId)
          .single();

        if (caseError || !caseData) {
          return NextResponse.json({ error: 'Case not found' }, { status: 404 });
        }

        // Validate case is in a decidable state
        const decidableStatuses: CaseStatus[] = ['review', 'processing', 'escalated'];
        if (!decidableStatuses.includes(caseData.status as CaseStatus)) {
          return NextResponse.json(
            {
              error: `Case cannot be decided in current status: ${caseData.status}. Case must be in review, processing, or escalated status.`,
            },
            { status: 409 },
          );
        }

        // Map decision to new case status
        const statusMap: Record<string, CaseStatus> = {
          approved: 'approved',
          denied: 'denied',
          escalated: 'escalated',
        };
        const newStatus = statusMap[validated.decision];

        // Update the case with the decision
        const { error: updateError } = await supabase
          .from('cases')
          .update({
            status: newStatus,
            decision: validated.decision,
            decision_justification: validated.justification,
            officer_id: validated.officer_id,
          })
          .eq('id', caseId);

        if (updateError) {
          return NextResponse.json(
            { error: 'Failed to update case: ' + updateError.message },
            { status: 500 },
          );
        }

        // AUDIT LOG: Record the human decision (DASH-05, REG-04)
        await logHumanDecision(caseId, {
          decision: validated.decision,
          justification: validated.justification,
          officer_id: validated.officer_id,
          officer_name: validated.officer_name,
          case_risk_score: caseData.risk_score ?? undefined,
          case_risk_level: caseData.risk_level ?? undefined,
          previous_status: caseData.status as CaseStatus,
          new_status: newStatus,
        });

        return NextResponse.json({
          success: true,
          case_id: caseId,
          decision: validated.decision,
          new_status: newStatus,
          officer_id: validated.officer_id,
          timestamp: new Date().toISOString(),
          message: `Case ${validated.decision} by officer ${validated.officer_id}`,
        });
      } catch (error) {
        // Handle validation errors with specific status codes
        if (error instanceof DecisionValidationError) {
          return NextResponse.json(
            {
              error: error.message,
              field: error.field,
              regulatory_requirement: true,
            },
            { status: error.statusCode },
          );
        }

        // Handle unexpected errors
        return NextResponse.json(
          { error: error instanceof Error ? error.message : 'Internal server error' },
          { status: 500 },
        );
      }
    }
    ```

    **2. Create `src/app/api/cases/[id]/str/route.ts`:**

    STR (Suspicious Transaction Report) filing referral endpoint. This is EXCLUSIVELY human per FINTRAC.

    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { createServerSupabaseClient } from '@/lib/supabase/server';
    import { validateSTRAuthority, DecisionValidationError } from '@/lib/audit/guards';
    import { logHumanDecision, logSystemEvent, AUDIT_ACTIONS } from '@/lib/audit/logger';
    import { CaseStatus } from '@/types';

    // FINTRAC regulatory context — returned to the client for display
    const FINTRAC_STR_CONTEXT = {
      regulation: 'Proceeds of Crime (Money Laundering) and Terrorist Financing Act (PCMLTFA)',
      requirement: 'Section 7 — Reporting of suspicious transactions',
      summary: 'A reporting entity must submit a Suspicious Transaction Report (STR) to FINTRAC when there are reasonable grounds to suspect that a transaction or attempted transaction is related to the commission or attempted commission of a money laundering or terrorist activity financing offence.',
      human_only_rationale: 'The determination of "reasonable grounds to suspect" requires human judgment and cannot be delegated to automated systems. OSFI Guideline E-23 explicitly flags AI-driven compliance decisions as requiring human oversight.',
      filing_deadline: 'STRs must be filed with FINTRAC within 30 days of the determination.',
      record_keeping: 'All STR-related records must be retained for at least 5 years from the date of the last business transaction or activity.',
    };

    export async function POST(
      request: NextRequest,
      { params }: { params: Promise<{ id: string }> }
    ) {
      const { id: caseId } = await params;

      try {
        const body = await request.json();

        // REGULATORY GUARD: Validate human authority for STR (REG-03)
        const validated = validateSTRAuthority(body);

        const supabase = createServerSupabaseClient();

        // Load current case
        const { data: caseData, error: caseError } = await supabase
          .from('cases')
          .select('*')
          .eq('id', caseId)
          .single();

        if (caseError || !caseData) {
          return NextResponse.json({ error: 'Case not found' }, { status: 404 });
        }

        // Update case status to escalated and mark for STR
        const { error: updateError } = await supabase
          .from('cases')
          .update({
            status: 'escalated' as CaseStatus,
            decision: 'escalated',
            decision_justification: `STR REFERRAL: ${validated.reason}`,
            officer_id: validated.officer_id,
          })
          .eq('id', caseId);

        if (updateError) {
          return NextResponse.json(
            { error: 'Failed to update case: ' + updateError.message },
            { status: 500 },
          );
        }

        // AUDIT LOG: Record the STR referral decision (DASH-05, REG-03, REG-04)
        await logHumanDecision(caseId, {
          decision: 'str_referral',
          justification: validated.reason,
          officer_id: validated.officer_id,
          officer_name: validated.officer_name,
          case_risk_score: caseData.risk_score ?? undefined,
          case_risk_level: caseData.risk_level ?? undefined,
          previous_status: caseData.status as CaseStatus,
          new_status: 'escalated',
        });

        // Log suspicious indicators as separate system event for audit completeness
        if (validated.suspicious_indicators.length > 0) {
          await logSystemEvent(caseId, AUDIT_ACTIONS.STR_REFERRED, {
            description: `STR referral initiated by ${validated.officer_id}. Suspicious indicators: ${validated.suspicious_indicators.join('; ')}`,
            metadata: {
              suspicious_indicators: validated.suspicious_indicators,
              officer_id: validated.officer_id,
            },
          });
        }

        return NextResponse.json({
          success: true,
          case_id: caseId,
          str_referral: {
            officer_id: validated.officer_id,
            reason: validated.reason,
            suspicious_indicators: validated.suspicious_indicators,
            timestamp: new Date().toISOString(),
            status: 'referred_for_str_filing',
          },
          // Return regulatory context for the UI to display
          regulatory_context: FINTRAC_STR_CONTEXT,
          message: 'Case referred for STR filing. This action has been recorded in the audit trail. FINTRAC filing must be completed within 30 days.',
        });
      } catch (error) {
        if (error instanceof DecisionValidationError) {
          return NextResponse.json(
            {
              error: error.message,
              field: error.field,
              regulatory_requirement: true,
              // Always return FINTRAC context on STR validation errors
              regulatory_context: FINTRAC_STR_CONTEXT,
            },
            { status: error.statusCode },
          );
        }

        return NextResponse.json(
          { error: error instanceof Error ? error.message : 'Internal server error' },
          { status: 500 },
        );
      }
    }

    // GET endpoint returns FINTRAC context for the STR filing UI
    export async function GET(
      request: NextRequest,
      { params }: { params: Promise<{ id: string }> }
    ) {
      const { id: caseId } = await params;

      const supabase = createServerSupabaseClient();

      // Load case to show current risk context
      const { data: caseData } = await supabase
        .from('cases')
        .select('id, status, risk_score, risk_level, applicant_name')
        .eq('id', caseId)
        .single();

      return NextResponse.json({
        case_id: caseId,
        case_summary: caseData ? {
          applicant_name: caseData.applicant_name,
          status: caseData.status,
          risk_score: caseData.risk_score,
          risk_level: caseData.risk_level,
        } : null,
        regulatory_context: FINTRAC_STR_CONTEXT,
        notice: 'STR filing is exclusively a human responsibility. AI systems have flagged potential indicators, but the determination of "reasonable grounds to suspect" must be made by a designated compliance officer.',
      });
    }
    ```

    IMPORTANT: Use Next.js 15 dynamic route params — `params` is a Promise that must be awaited.

    IMPORTANT: The decision endpoint (decide/route.ts) may overlap with an existing endpoint from Phase 6/8. If an existing endpoint exists at this path, this plan's version REPLACES it with full audit logging and regulatory guards. The executor should check for existing files and merge any additional logic.
  </action>
  <verify>
    - `npx tsc --noEmit` passes for both new route files
    - POST /api/cases/[id]/decide:
      - Without officer_id: returns 400 with REG-02 violation message
      - With AI-like officer_id (e.g., "agent-system"): returns 403 with REG-02 violation
      - Without justification: returns 400 with REG-04 violation message
      - With short justification (< 10 chars): returns 400
      - With valid request: returns 200 with decision confirmation
      - Case status updated in Supabase
      - Audit log entry created via logHumanDecision
    - POST /api/cases/[id]/str:
      - Without officer_id: returns 400 with REG-03 violation message
      - With valid request: returns 200 with STR referral details + FINTRAC context
      - Case status updated to 'escalated'
      - Audit log entries created (decision + system event)
    - GET /api/cases/[id]/str:
      - Returns FINTRAC regulatory context and case summary
    - All endpoints use await params for Next.js 15 compatibility
  </verify>
  <done>Human-in-the-loop enforcement implemented at the API layer. Decision endpoint requires human officer_id, valid decision, and mandatory justification — rejects AI actors. STR endpoint is exclusively human with FINTRAC regulatory context returned to the UI. All decisions logged to audit trail.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes for all new files
2. validateHumanDecision rejects requests without officer_id (400)
3. validateHumanDecision rejects AI-like actor IDs (403)
4. validateHumanDecision rejects missing or short justification (400)
5. validateSTRAuthority applies same human-only validation plus STR-specific checks
6. Decision endpoint updates case status and logs to audit trail
7. STR endpoint marks case as escalated and returns FINTRAC regulatory context
8. Error messages cite specific regulatory requirements (REG-01, REG-02, REG-03, REG-04)
</verification>

<success_criteria>
- AI cannot make final account decisions — server-side validation rejects non-human actors (REG-01, REG-02)
- All decision endpoints require mandatory justification for FINTRAC record-keeping (REG-04)
- STR filing workflow is exclusively human with full FINTRAC regulatory context (REG-03)
- Every decision is logged through the audit system with who/what/when/why (DASH-05)
- Guard functions are reusable — any future decision endpoint can call validateHumanDecision
</success_criteria>

<output>
After completion, create `.planning/phases/09-regulatory-audit-trail/09-02-SUMMARY.md`
</output>

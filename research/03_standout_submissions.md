# What Makes Standout AI Builder Portfolio Submissions

## Executive Summary

Winning AI demos share a consistent DNA: they solve a real problem for a specific user, communicate the "why" in under 30 seconds, show a working product (not a slide deck), and reveal the builder's judgment and taste -- not just their technical chops. For a Wealthsimple AI Builders submission, this means aligning your demo to Wealthsimple's values of simplicity, client obsession, and maker-owner culture while demonstrating production-quality thinking in a 2-3 minute window.

---

## 1. Patterns From Winning AI Hackathon Projects

### What Judges Actually Look For

Research across Devpost, Microsoft AI Agents Hackathon, LlamaCon Hackathon, and MIT Global AI Hackathon reveals consistent judging criteria:

1. **Innovation** -- Is this a novel application of AI, or a wrapper on an existing API?
2. **Impact** -- Does it solve a real problem for real people?
3. **Technical Quality** -- Does it actually work? Is the implementation sound?
4. **Usability** -- Can someone use it without a tutorial?
5. **Presentation** -- Can you communicate why this matters in 60 seconds?

### Functionality vs. Polish: The Real Answer

The evidence is clear: **functionality and problem relevance beat visual polish every time**, but a baseline level of polish is table stakes.

- A hackathon judge recounts a flashy AR app with a weak problem statement losing to a simple SMS-based system connecting rural patients with doctors. "The UI was basic and code wasn't perfect, but the relevance was undeniable."
- However, judges also note: "Clean UI, intuitive flows, and even a thoughtful pitch deck can elevate a project from 'good' to 'great'."
- Projects that are "extremely back-end heavy and have almost no front end" or vice versa consistently underperform.

**Bottom line**: Polish enough to show you care about users. Functional enough to prove it works. Deep enough to show you understand the problem domain.

### Common Mistakes That Kill Submissions

- Not fulfilling basic requirements (surprisingly common)
- Shoehorning AI where it does not belong ("just add AI" syndrome)
- Generic chatbot wrappers with no domain specificity
- No working demo -- only slides or mockups
- Verbose, unclear explanations that bury the core value

Sources: [Devpost hackathon judging tips](https://info.devpost.com/blog/hackathon-judging-tips), [Klaviyo: How to Win an AI Hackathon](https://klaviyo.tech/how-to-win-an-ai-hackathon-build-a-solution-that-actually-matters-aab49307587e), [TAIKAI judging criteria](https://taikai.network/en/blog/hackathon-judging)

---

## 2. Lessons From YC Demo Day and Product Hunt AI Launches

### YC Demo Day Patterns (2024-2025)

The YC format forces extreme clarity: ~1 minute, ~1 slide. Key patterns from successful AI startups:

- **Category-defining framing**: The best pitches "redefine categories with AI at the core" rather than describing incremental improvements
- **Concrete traction**: Revenue, users, deals with named customers -- proof over promises
- **Lean efficiency**: Startups with $1M-$10M ARR and fewer than 10 people demonstrate AI-native leverage
- **Vertical specificity**: Winners applied AI to estate planning, clinical trials, customs clearance -- not "general-purpose AI assistant"
- **10% weekly growth**: The 2025 batch averaged 10% weekly revenue growth, an unprecedented pace

The "vertebrae" framework from YC's official guide recommends identifying 3-4 core points your audience will remember:
- What are we building and for whom?
- Why hasn't this been done before / why is it hard?
- Why is this an opportunity not to be missed?

### Product Hunt AI Launch Patterns

- **First impressions are everything**: The algorithm weighs first-hour upvotes 4x more than later ones
- **Comments > upvotes**: Engagement depth matters more than vanity metrics
- **Demo quality is the filter**: "If your story is clear, your demo assets will naturally become more compelling"
- **Only 10% get featured** (down from 60-98% pre-2024): Quality bar has risen dramatically

Sources: [YC Demo Day Guide](https://www.ycombinator.com/blog/guide-to-demo-day-pitches/), [TechCrunch YC Coverage](https://techcrunch.com/2024/09/26/9-startups-that-stood-out-on-yc-demo-day-2/), [Jeffrey Paine on YC 2025](https://jeffreypaine.com/my-first-yc-demo-day-in-2025-chaos-genius-and-why-this-batch-feels-like-the-future)

---

## 3. What Makes an AI Portfolio Signal "This Person Gets It"

### The Hiring Evaluator Perspective

Research across AI hiring managers and portfolio evaluators reveals what separates memorable candidates:

**Five strategic projects beat twenty mediocre ones.** Evaluators scan for:

1. **Real business problems solved** -- document processing, customer service automation, content moderation -- not toy demos
2. **Measurable impact with specific metrics** -- processing speed, accuracy rates, cost reduction, time savings
3. **Production thinking** -- error handling, security, scalability, audit trails shown (not just mentioned)
4. **Domain specificity** -- "A financial data extractor beats a generic image classifier; a code review assistant beats another chatbot wrapper"
5. **Decision-making transparency** -- "Walk through why you picked a specific architecture, how you dealt with noisy inputs, what failed, and what you learned"

### The 30-Second Test

"In the first 30 seconds, hiring managers should know what your project does, why it matters, and how to run it." Polished live demos and clear documentation are the primary filters for who gets a closer look.

### The "Yet Another Chatbot" Problem

"Nobody is impressed by 'Yet Another GPT Chatbot.'" Generic Streamlit apps wrapping pre-trained models with minimal customization are invisible to evaluators. What stands out:
- Compound AI systems with multiple interacting components
- Projects showing progression from simple to complex
- Honest documentation of limitations and tradeoffs
- Architecture diagrams and clear technical writing

Sources: [AI Engineering Portfolio Guide](https://zenvanriel.nl/ai-engineer-blog/100k-ai-engineering-portfolio-projects/), [ProjectPro AI Portfolio](https://www.projectpro.io/article/artificial-intelligence-portfolio/1140), [KDnuggets Portfolio Projects](https://www.kdnuggets.com/7-ai-portfolio-projects-to-boost-the-resume)

---

## 4. Anatomy of a Compelling 2-3 Minute Demo

### The Structure That Works

Based on YC Demo Day format, hackathon presentations, and product demo best practices:

| Time | Segment | What to Do |
|------|---------|------------|
| 0:00-0:15 | **Hook** | Bold stat, surprising insight, or pain point that resonates immediately |
| 0:15-0:30 | **Problem** | One sentence: who has this problem and why it matters |
| 0:30-0:45 | **Solution** | One sentence: what you built and how it works conceptually |
| 0:45-2:00 | **Live Demo** | Show the product working end-to-end on a real scenario |
| 2:00-2:30 | **Impact** | Metrics, results, what this means for the user |
| 2:30-2:45 | **Architecture** | Quick flash of technical depth (optional but powerful) |
| 2:45-3:00 | **Close** | Why this matters, what's next |

### Demo Delivery Best Practices

- **Speak slowly and clearly** -- especially with technical content
- **One main point per visual** -- 7 words maximum on any slide
- **Never turn your back** on the camera/audience to look at slides
- **Have a backup plan** -- pre-recorded segments or screenshots in case of technical failure
- **Practice until it feels natural** -- record yourself and iterate
- **Show, don't tell** -- live product usage > slides about the product

### Critical Mistakes to Avoid in a Demo Video

- Starting with "Hi, my name is..." instead of the hook
- Spending 60+ seconds on the problem before showing the product
- Including jargon, buzzwords, or unnecessarily complex language
- Screen recordings with no voiceover or context
- Demo that requires setup explanation ("First you need to install...")
- Ending without a clear impact statement

Sources: [YC Demo Day Pitch Guide](https://www.ycombinator.com/blog/guide-to-demo-day-pitches/), [Storylane Demo Presentation Guide](https://www.storylane.io/blog/how-to-prepare-a-great-software-demo-presentation)

---

## 5. Wealthsimple Leadership on AI and What They Value

### Mike Katchen (CEO) on AI

Katchen takes a **bullish but pragmatic** approach to AI:
- Compares AI tools to "Microsoft Word" (productivity gains) rather than a transformative platform shift
- Focus on **reducing administrative friction** and helping teams adopt tools across engineering, CS, and content
- Skeptical of doomsday AI narratives: "I for one am not a doomsday AI believer"
- Believes the future of financial services is **seamless product integration** -- making products work together so "the value of doing something with Wealthsimple gets better"
- Emphasizes **dogfooding**: builders must be customers of their own product
- Recruiting philosophy: "really sharp people who make us better"

### Wealthsimple Engineering AI Strategy (5 Principles)

From the engineering blog (authored by Cassia Scheffer, Staff Software Developer):

1. **Engineering fundamentals remain paramount** -- Critical thinking and problem-solving stay essential despite AI tools
2. **AI changes methodology, not purpose** -- Tools shift *how* work gets done, not *why* it matters
3. **Quality codebases benefit AI** -- "A codebase with coherent design principles, clear test output, excellent docs, and informative logging is a joy for developers"
4. **Maker-owner culture** -- Developers choose and customize their AI tools
5. **Simplicity first** -- Not every task requires LLMs

Key stats: 85% of developers use GitHub Copilot, 50% use Cursor, and their LLM Gateway serves 500 internal users daily.

### Mandy Gu (Former Senior Engineering Manager, ML & Data) on GenAI

Led the team that built Wealthsimple's LLM Gateway and internal AI tools:
- LLM Gateway launched April 2023, now serving 500+ daily users
- Built "Boosterpack" -- an internal AI assistant with personalized knowledge bases
- Learned hard lessons: "not all their bets had paid off" -- pivoted from chasing cutting-edge models to **business alignment**
- Usage breakdown: ~40% code generation, ~30% content creation, ~27% information retrieval
- Key insight: "Tools are most valuable when injected in places they do work"

### Wealthsimple's AI Product Direction

- Acquired Montreal's **Fey** to build an AI-powered research-and-trading dashboard
- Dashboard enables natural language stock lookup, performance analysis, and market driver summaries
- Launching Q4 2025 to Q1 2026
- Three AI streams: employee productivity, operations optimization for client experience, and an LLM platform enabling both

Sources: [Wealthsimple Engineering AI Strategy](https://engineering.wealthsimple.com/wealthsimples-engineering-ai-strategy), [Wealthsimple LLM Gateway](https://engineering.wealthsimple.com/get-to-know-our-llm-gateway-and-how-it-provides-a-secure-and-reliable-space-to-use-generative-ai), [Mike Katchen Podcast](https://markmacleod.me/wealthsimples-mike-katchen-on-challenging-canadas-banking-oligopoly-achieving-profitable-growth-and-building-for-the-future/), [QCon Mandy Gu Talk](https://www.infoq.com/news/2024/11/qcon-sf-genai-productivity/)

---

## 6. Wealthsimple's Culture and What It Means for Submissions

### Core Values That Should Inform Your Demo

1. **"The client, the client, the client"** -- Start from a real user problem, not a cool technology
2. **"Ship it"** -- Bias toward execution; show a working product, not a plan
3. **"Simple is better"** -- Expertise means making complexity accessible; do not over-engineer
4. **"Naive ambition"** -- Ask "how can we do this?" not "can we do this?"
5. **Maker-owner mentality** -- Engineers are "problem solvers, not task takers"

### Reading Between the Lines: What Wealthsimple Wants to See

Based on their public statements, blog posts, and culture:

- **Pragmatic AI application** -- They explicitly say "not every task requires LLMs." Show judgment about when and where AI adds value.
- **Security and compliance awareness** -- Their LLM Gateway was built around PII protection. In fintech, responsible AI is not optional.
- **Business alignment over technical novelty** -- Their team pivoted away from chasing cutting-edge models toward practical business impact. Demonstrate the same maturity.
- **Production thinking** -- They care about clean codebases, clear error messages, and developer experience. Show code quality, not just working code.
- **Dogfooding mentality** -- Build something you would actually use as a Wealthsimple customer.

Sources: [Wealthsimple Culture](https://www.wealthsimple.com/en-ca/culture), [Engineering Team Page](https://engineering.wealthsimple.com/meet-the-engineering-team)

---

## 7. Synthesis: The Standout Submission Checklist

A submission that makes evaluators say "this person gets it" will:

### Problem & Relevance
- [ ] Solve a specific, real problem that a Wealthsimple user or employee actually has
- [ ] Frame the problem in 1-2 sentences that anyone can understand
- [ ] Show domain understanding of finance/fintech, not just generic AI knowledge

### Technical Execution
- [ ] Have a working demo -- not a mockup, not a slide deck
- [ ] Use AI where it genuinely adds value (not AI for AI's sake)
- [ ] Show production-quality thinking: error handling, security awareness, scalable design
- [ ] Demonstrate a compound/multi-step AI system, not a single API call

### Demo Quality
- [ ] Hook in the first 15 seconds with a bold stat or relatable pain point
- [ ] Show the product working end-to-end in a real scenario
- [ ] Keep to 2-3 minutes with tight pacing
- [ ] Include measurable impact or results
- [ ] Have clean, professional presentation without over-production

### Judgment & Taste
- [ ] Show tradeoff decisions (why this approach vs. alternatives)
- [ ] Acknowledge limitations honestly
- [ ] Demonstrate simplicity ("simple is better") -- solve the problem elegantly
- [ ] Align with Wealthsimple's values: client focus, execution speed, maker-owner mentality

### Differentiation
- [ ] Avoid "Yet Another Chatbot" territory
- [ ] Build for a specific vertical/domain rather than a generic tool
- [ ] Show something that makes the evaluator think "I wish we had this internally"
- [ ] Demonstrate understanding of fintech-specific constraints (PII, compliance, trust)
